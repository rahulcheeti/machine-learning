{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1prog3",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulcheeti/machine-learning/blob/master/hw1prog3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4Hql0-BEtiY4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code is not able to update Weights in back-propagation modulue....All the best if you can fix it and make it run"
      ]
    },
    {
      "metadata": {
        "id": "1CXG5xjlUpfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import math\n",
        "\n",
        "lear_rate = 0.005\n",
        "batch_size = 100\n",
        "experiments = 40\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = (x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "#y_train = (keras.utils.to_categorical(y_train,10))\n",
        "\n",
        "x_test = (x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
        "y_te = y_test\n",
        "y_test = (keras.utils.to_categorical(y_test,10))\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-FEzufCVA4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "  W = abs(np.random.randn(10,784)*0.01)\n",
        "  b = abs(np.random.randn(10,1)*0.01)\n",
        "  return W,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ZvSXEPsVM1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(W,b,x):\n",
        "  output = (np.transpose(np.dot(W,np.transpose(x)) + b))\n",
        "  summation = 0\n",
        "  eps = 0.00001\n",
        "  for i in range(len(x)):\n",
        "    summation = 0\n",
        "    for j in range(len(output[1])):\n",
        "      summation += np.exp(output[i][j]) + eps\n",
        "    output[i] = np.exp(output[i])/summation\n",
        "  output = np.transpose(output)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LKoebQMe5B-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7be5e752-f40c-4816-8878-5064ed9ab267"
      },
      "cell_type": "code",
      "source": [
        "W,b = initialize_parameters()\n",
        "output = forward_propagation(W,b,x_train[0:20])\n",
        "print(W)\n",
        "W,b = backward_propagation(x_train[0:20],y_train[0:20],output,W,b,lear_rate,batch_size)\n",
        "print(W)\n",
        "output = forward_propagation(W,b,x_train[0:20])\n",
        "output = abs(output)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00656409 0.00933824 0.00244751 ... 0.00513231 0.01721452 0.00588277]\n",
            " [0.00903868 0.00214392 0.01016364 ... 0.00858687 0.00702496 0.00345712]\n",
            " [0.013738   0.02290493 0.01445875 ... 0.00678036 0.00097187 0.00755343]\n",
            " ...\n",
            " [0.00837847 0.00793448 0.00275715 ... 0.01206173 0.01014607 0.00446139]\n",
            " [0.00090516 0.0071681  0.00306473 ... 0.00079337 0.01478636 0.0059363 ]\n",
            " [0.00597226 0.0122195  0.00329775 ... 0.03145784 0.00234045 0.00220187]]\n",
            "[[0.00656409 0.00933824 0.00244751 ... 0.00513231 0.01721452 0.00588277]\n",
            " [0.00903868 0.00214392 0.01016364 ... 0.00858687 0.00702496 0.00345712]\n",
            " [0.013738   0.02290493 0.01445875 ... 0.00678036 0.00097187 0.00755343]\n",
            " ...\n",
            " [0.00837847 0.00793448 0.00275715 ... 0.01206173 0.01014607 0.00446139]\n",
            " [0.00090516 0.0071681  0.00306473 ... 0.00079337 0.01478636 0.0059363 ]\n",
            " [0.00597226 0.0122195  0.00329775 ... 0.03145784 0.00234045 0.00220187]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ub2BMyGKVVYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_function(y_train,output,batch_size):\n",
        "  loss = np.sum(np.multiply((np.transpose(y_train) - output),(np.transpose(y_train) - output))/2,axis=1,keepdims=True)/batch_size\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Nsdg0vfVYpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backward_propagation(x_train,y_train,output,W_a,b_a,lear_rate,batch_size):\n",
        "  #print(output.shape)\n",
        "  #der_bet = output - np.transpose(y_train)\n",
        "    #print(der_bet)\n",
        "    #der_bet = np.sum(abs(der_bet, axis = 0, keepdims = True)\n",
        "    #print(der_bet)\n",
        "    #der_bet = der_bet\n",
        "    #print(der_bet)\n",
        "  #der_z = der_bet\n",
        "  #print(der_z)\n",
        "  #der_W = np.dot(der_z,x_train)\n",
        "  #der_b = np.sum(der_z, axis =1 ,keepdims = True)\n",
        "  #print(der_W.shape)\n",
        "  #print(der_W)\n",
        "  #print(der_b)\n",
        "  der_loss = output - np.transpose(y_train)\n",
        "  der_W = np.dot(der_loss,x_train)\n",
        "  der_b = np.sum(der_loss,axis=1,keepdims=True)\n",
        "  W_a = W_a - (lear_rate*der_W)\n",
        "  b_a = b_a - lear_rate*der_b\n",
        "  #print(W)\n",
        "  #print(b)\n",
        "  return W_a, b_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nqBtZhwpoa6",
        "colab_type": "code",
        "outputId": "60e931e0-7fb5-4e29-a20b-eb0fdd3f7d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "W,b = initialize_parameters()\n",
        "output = forward_propagation(W,b,x_train[0:60000])\n",
        "W,b = backward_propagation(x_train[0:60000],y_train[0:60000],output,W,b,lear_rate,batch_size)\n",
        "out = forward_propagation(W,b,x_test)\n",
        "out = np.transpose(out)\n",
        "out_list = []\n",
        "\n",
        "for i in range(10000):\n",
        "  out_list.append(np.argmax(out[i]))\n",
        "count = 0\n",
        "for i in range(10000):\n",
        "  if out_list[i] == y_te[i]:\n",
        "    count += 1\n",
        "out_list = []\n",
        "acc = count/100\n",
        "print(count,\"/10000\")\n",
        "print(\"accuracy:\",acc)\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "980 /10000\n",
            "accuracy: 9.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "r9WkxtrXVdKU",
        "colab_type": "code",
        "outputId": "a006fe13-1b5b-4ad9-bb5b-0e0a71e26c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "cell_type": "code",
      "source": [
        "W,b = initialize_parameters()\n",
        "for j in range(experiments):\n",
        "  for i in range(0, len(x_train), batch_size):\n",
        "    output = forward_propagation(W,b,x_train[i:i+batch_size])\n",
        "    W,b = backward_propagation(x_train[i:i+batch_size],y_train[i:i+batch_size],output,W,b,lear_rate,batch_size)\n",
        "    #output = forward_propagation(W,b,x_train[0:60000])\n",
        "    #W,b = backward_propagation(x_train[0:60000],y_train[0:60000],output,W,b,lear_rate,batch_size)\n",
        "  out = forward_propagation(W,b,x_test)\n",
        "  out = np.transpose(out)\n",
        "  out_list = list()\n",
        "  for i in range(10000):\n",
        "    out_list.append(np.argmax(out[i]))\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    if out_list[i] == y_te[i]:\n",
        "      count += 1\n",
        "  out_list = []\n",
        "  acc = count/100\n",
        "  print(\"epoch:\",j)\n",
        "  print(count,\"/10000\")\n",
        "  print(\"accuracy:\",acc)\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "980 /10000\n",
            "accuracy: 9.8\n",
            "epoch: 1\n",
            "980 /10000\n",
            "accuracy: 9.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-58bbce54f296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlear_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#output = forward_propagation(W,b,x_train[0:60000])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#W,b = backward_propagation(x_train[0:60000],y_train[0:60000],output,W,b,lear_rate,batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-f0a300a3d701>\u001b[0m in \u001b[0;36mbackward_propagation\u001b[0;34m(x_train, y_train, output, W_a, b_a, lear_rate, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#print(der_b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mder_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mder_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mder_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mder_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mder_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mW_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_a\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlear_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mder_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZslI44LDAXUG",
        "colab_type": "code",
        "outputId": "887b6bab-6bf2-44fd-c8c6-b896a145891e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "cell_type": "code",
      "source": [
        "W,b = initialize_parameters()\n",
        "for j in range(experiments):\n",
        "  #for i in range(0, len(x_train), batch_size):\n",
        "    #output = forward_propagation(W,b,x_train[i:i+batch_size])\n",
        "    #W,b = backward_propagation(x_train[i:i+batch_size],y_train[i:i+batch_size],output,W,b,lear_rate,batch_size)\n",
        "  output = forward_propagation(W,b,x_train[0:60000])\n",
        "  W,b = backward_propagation(x_train[0:60000],y_train[0:60000],output,W,b,lear_rate,batch_size)\n",
        "  out = forward_propagation(W,b,x_test)\n",
        "  out = np.transpose(out)\n",
        "  out_list = []\n",
        "  for i in range(10000):\n",
        "    out_list.append(np.argmax(out[i]))\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    if out_list[i] == y_te[i]:\n",
        "      count += 1\n",
        "  out_list = []\n",
        "  acc = count/100\n",
        "  print(\"epoch:\",j)\n",
        "  print(count,\"/10000\")\n",
        "  print(\"accuracy:\",acc)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "980 /10000\n",
            "accuracy: 9.8\n",
            "epoch: 1\n",
            "980 /10000\n",
            "accuracy: 9.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-6ca80332bd2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlear_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mout_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-a1cc1359d4c2>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(W, b, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0msummation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msummation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}