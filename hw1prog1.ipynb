{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1prog1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulcheeti/machine-learning/blob/master/hw1prog1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fZB-hwHD1I3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6bea3be-c3fb-481a-db1d-1466ffdc09dd"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import math\n",
        "\n",
        "lear_rate = 0.005\n",
        "batch_size = 100\n",
        "experiments = 40\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = (x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
        "y_train = (keras.utils.to_categorical(y_train,10))\n",
        "\n",
        "x_test = (x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
        "y_te = y_test\n",
        "y_test = (keras.utils.to_categorical(y_test,10))\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GAU-nYDYu_GX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "  W = np.random.randn(10,784)*0.01\n",
        "  b = np.random.randn(10,1)*0.01\n",
        "  return W,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8oKMyM9wIty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(W,b,x):\n",
        "  output = np.dot(W,np.transpose(x)) + (b)\n",
        "  output = sigmoid(output)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDXpF8_wzfoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  z = 1/(1+np.exp(-x))\n",
        "  return z  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSJ3GZLF05P4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_function(y_train,output,batch_size):\n",
        "  loss = np.sum(np.multiply((np.transpose(y_train) - output),(np.transpose(y_train) - output))/2,axis=1,keepdims=True)/batch_size\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbvR3s8cO0wN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backward_propagation(x_train,y_train,output,W,b,lear_rate,batch_size):\n",
        "  \n",
        "  der_loss = -(np.transpose(y_train) - output)\n",
        "  der_sig = sigmoid(output)*(1 - sigmoid(output))\n",
        "  der_z = np.multiply(der_loss,der_sig)\n",
        "  der_W = np.dot(der_z,x_train)\n",
        "  der_b = np.sum(der_z,axis=1,keepdims=True)\n",
        "  W = W - lear_rate*der_W\n",
        "  b = b - lear_rate*der_b\n",
        "  return W,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1B-X6iIjzEoU",
        "colab_type": "code",
        "outputId": "2649f578-1106-477b-93c8-9975864e7254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2057
        }
      },
      "cell_type": "code",
      "source": [
        "W,b = initialize_parameters()\n",
        "for j in range(experiments):\n",
        "  for i in range(0, x_train.shape[0], batch_size):\n",
        "    output = forward_propagation(W,b,x_train[i:i+batch_size])\n",
        "    W,b = backward_propagation(x_train[i:i+batch_size],y_train[i:i+batch_size],output,W,b,lear_rate,batch_size)\n",
        "  out = forward_propagation(W,b,x_test)\n",
        "  out = np.transpose(out)\n",
        "  out_list = list()\n",
        "  for i in range(10000):\n",
        "    out_list.append(np.argmax(out[i]))\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    if out_list[i] == y_te[i]:\n",
        "      count += 1\n",
        "  acc = count/100\n",
        "  print(\"epoch:\",j)\n",
        "  print(count,\"/10000\")\n",
        "  print(\"accuracy:\",acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "8946 /10000\n",
            "accuracy: 89.46\n",
            "epoch: 1\n",
            "9043 /10000\n",
            "accuracy: 90.43\n",
            "epoch: 2\n",
            "9076 /10000\n",
            "accuracy: 90.76\n",
            "epoch: 3\n",
            "9099 /10000\n",
            "accuracy: 90.99\n",
            "epoch: 4\n",
            "9106 /10000\n",
            "accuracy: 91.06\n",
            "epoch: 5\n",
            "9121 /10000\n",
            "accuracy: 91.21\n",
            "epoch: 6\n",
            "9128 /10000\n",
            "accuracy: 91.28\n",
            "epoch: 7\n",
            "9138 /10000\n",
            "accuracy: 91.38\n",
            "epoch: 8\n",
            "9142 /10000\n",
            "accuracy: 91.42\n",
            "epoch: 9\n",
            "9147 /10000\n",
            "accuracy: 91.47\n",
            "epoch: 10\n",
            "9148 /10000\n",
            "accuracy: 91.48\n",
            "epoch: 11\n",
            "9153 /10000\n",
            "accuracy: 91.53\n",
            "epoch: 12\n",
            "9157 /10000\n",
            "accuracy: 91.57\n",
            "epoch: 13\n",
            "9155 /10000\n",
            "accuracy: 91.55\n",
            "epoch: 14\n",
            "9156 /10000\n",
            "accuracy: 91.56\n",
            "epoch: 15\n",
            "9158 /10000\n",
            "accuracy: 91.58\n",
            "epoch: 16\n",
            "9155 /10000\n",
            "accuracy: 91.55\n",
            "epoch: 17\n",
            "9155 /10000\n",
            "accuracy: 91.55\n",
            "epoch: 18\n",
            "9160 /10000\n",
            "accuracy: 91.6\n",
            "epoch: 19\n",
            "9160 /10000\n",
            "accuracy: 91.6\n",
            "epoch: 20\n",
            "9158 /10000\n",
            "accuracy: 91.58\n",
            "epoch: 21\n",
            "9160 /10000\n",
            "accuracy: 91.6\n",
            "epoch: 22\n",
            "9160 /10000\n",
            "accuracy: 91.6\n",
            "epoch: 23\n",
            "9161 /10000\n",
            "accuracy: 91.61\n",
            "epoch: 24\n",
            "9162 /10000\n",
            "accuracy: 91.62\n",
            "epoch: 25\n",
            "9164 /10000\n",
            "accuracy: 91.64\n",
            "epoch: 26\n",
            "9163 /10000\n",
            "accuracy: 91.63\n",
            "epoch: 27\n",
            "9165 /10000\n",
            "accuracy: 91.65\n",
            "epoch: 28\n",
            "9168 /10000\n",
            "accuracy: 91.68\n",
            "epoch: 29\n",
            "9171 /10000\n",
            "accuracy: 91.71\n",
            "epoch: 30\n",
            "9171 /10000\n",
            "accuracy: 91.71\n",
            "epoch: 31\n",
            "9169 /10000\n",
            "accuracy: 91.69\n",
            "epoch: 32\n",
            "9173 /10000\n",
            "accuracy: 91.73\n",
            "epoch: 33\n",
            "9176 /10000\n",
            "accuracy: 91.76\n",
            "epoch: 34\n",
            "9177 /10000\n",
            "accuracy: 91.77\n",
            "epoch: 35\n",
            "9177 /10000\n",
            "accuracy: 91.77\n",
            "epoch: 36\n",
            "9176 /10000\n",
            "accuracy: 91.76\n",
            "epoch: 37\n",
            "9175 /10000\n",
            "accuracy: 91.75\n",
            "epoch: 38\n",
            "9176 /10000\n",
            "accuracy: 91.76\n",
            "epoch: 39\n",
            "9176 /10000\n",
            "accuracy: 91.76\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}