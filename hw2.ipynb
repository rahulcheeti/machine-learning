{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulcheeti/machine-learning/blob/master/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pUZcsaLSjI5h",
        "colab_type": "code",
        "outputId": "38c4a169-e081-4666-96e2-293464e1ae90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "for i in range(5):\n",
        "  x_val = np.array(x_train[i*10000:(i+1)*10000])\n",
        "  y_val = np.array(y_train[i*10000:(i+1)*10000])\n",
        "  \n",
        "  x_tra = np.array(x_train[0:i*10000]+x_train[(i+1)*10000:50000])\n",
        "  y_tra = np.array(y_train[0:i*10000]+y_train[(i+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "  score = model.evaluate(x_val, y_val, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print(score)\n",
        "  print(History.history)\n",
        "\n",
        "  plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "  plt.show(plotaccuracy)\n",
        "  \n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_acc'][-1])\n",
        "\n",
        "avg_val_loss = 0\n",
        "avg_val_acc = 0\n",
        "for i in range(5):\n",
        "  avg_val_loss += val_loss[i]/5\n",
        "  avg_val_acc += val_acc[i]/5\n",
        "  \n",
        "print('avgerage validation loss:',avg_val_loss)\n",
        "print('average validation accuracy:',avg_val_acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d2b864c9037b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m           validation_data=(x_val, y_val))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "R8D-vs4ewTMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "for i in range(5):\n",
        "  x_val = np.array(x_train[i*10000:(i+1)*10000])\n",
        "  y_val = np.array(y_train[i*10000:(i+1)*10000])\n",
        "  \n",
        "  x_tra = np.array(x_train[0:i*10000]+x_train[(i+1)*10000:50000])\n",
        "  y_tra = np.array(y_train[0:i*10000]+y_train[(i+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "  score = model.evaluate(x_val, y_val, verbose=0)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print(score)\n",
        "  print(History.history)\n",
        "\n",
        "  plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "  plt.show(plotaccuracy)\n",
        "  \n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_acc'][-1])\n",
        "\n",
        "avg_val_loss = 0\n",
        "avg_val_acc = 0\n",
        "for i in range(5):\n",
        "  avg_val_loss += val_loss[i]/5\n",
        "  avg_val_acc += val_acc[i]/5\n",
        "  \n",
        "print('avgerage validation loss:',avg_val_loss)\n",
        "print('average validation accuracy:',avg_val_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiWOVrSNUY0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First Architecture Training and Validation set"
      ]
    },
    {
      "metadata": {
        "id": "UU5GB5Qw1dF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4495
        },
        "outputId": "b217ee02-685c-4d23-f43d-8ffcb6efac89"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 53s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 24s 605us/step - loss: 1.8939 - acc: 0.2875\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 20s 501us/step - loss: 1.5866 - acc: 0.4158\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 24s 594us/step - loss: 1.4540 - acc: 0.4702\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 19s 486us/step - loss: 1.3653 - acc: 0.5058\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 1.2952 - acc: 0.5350\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 24s 593us/step - loss: 1.2443 - acc: 0.5556\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 23s 578us/step - loss: 1.2011 - acc: 0.5704\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 19s 486us/step - loss: 1.1600 - acc: 0.5872\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 23s 581us/step - loss: 1.1220 - acc: 0.6055\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 19s 484us/step - loss: 1.0897 - acc: 0.6110\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 20s 507us/step - loss: 0.9784 - acc: 0.6544 - val_loss: 0.8858 - val_acc: 0.6915\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 20s 498us/step - loss: 0.9337 - acc: 0.6691 - val_loss: 0.8819 - val_acc: 0.6870\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.8970 - acc: 0.6838 - val_loss: 0.8554 - val_acc: 0.6938\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.8662 - acc: 0.6958 - val_loss: 0.7941 - val_acc: 0.7233\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.8343 - acc: 0.7071 - val_loss: 0.7876 - val_acc: 0.7271\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.8057 - acc: 0.7164 - val_loss: 0.7674 - val_acc: 0.7309\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 21s 531us/step - loss: 0.7761 - acc: 0.7277 - val_loss: 0.7379 - val_acc: 0.7444\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 21s 532us/step - loss: 0.7493 - acc: 0.7350 - val_loss: 0.7315 - val_acc: 0.7479\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.7343 - acc: 0.7412 - val_loss: 0.7272 - val_acc: 0.7457\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.7069 - acc: 0.7536 - val_loss: 0.7367 - val_acc: 0.7434\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.6928 - acc: 0.7571 - val_loss: 0.6842 - val_acc: 0.7586\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.6697 - acc: 0.7647 - val_loss: 0.6844 - val_acc: 0.7648\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.6501 - acc: 0.7717 - val_loss: 0.6628 - val_acc: 0.7688\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.6310 - acc: 0.7772 - val_loss: 0.6590 - val_acc: 0.7667\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.6205 - acc: 0.7832 - val_loss: 0.6607 - val_acc: 0.7706\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.5971 - acc: 0.7898 - val_loss: 0.6483 - val_acc: 0.7742\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.5868 - acc: 0.7922 - val_loss: 0.6403 - val_acc: 0.7767\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.5740 - acc: 0.7984 - val_loss: 0.6278 - val_acc: 0.7827\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 21s 531us/step - loss: 0.5558 - acc: 0.8036 - val_loss: 0.6242 - val_acc: 0.7837\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.5438 - acc: 0.8079 - val_loss: 0.6195 - val_acc: 0.7878\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.5260 - acc: 0.8149 - val_loss: 0.6198 - val_acc: 0.7816\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.5158 - acc: 0.8182 - val_loss: 0.6072 - val_acc: 0.7931\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.5029 - acc: 0.8198 - val_loss: 0.6165 - val_acc: 0.7902\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 21s 529us/step - loss: 0.4929 - acc: 0.8245 - val_loss: 0.6140 - val_acc: 0.7894\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 21s 530us/step - loss: 0.4783 - acc: 0.8303 - val_loss: 0.6104 - val_acc: 0.7906\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.4653 - acc: 0.8358 - val_loss: 0.6004 - val_acc: 0.7937\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.4555 - acc: 0.8388 - val_loss: 0.6073 - val_acc: 0.7931\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.4421 - acc: 0.8438 - val_loss: 0.6192 - val_acc: 0.7900\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 20s 504us/step - loss: 0.4301 - acc: 0.8485 - val_loss: 0.6024 - val_acc: 0.7960\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.4250 - acc: 0.8491 - val_loss: 0.5980 - val_acc: 0.7987\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 20s 498us/step - loss: 0.4128 - acc: 0.8552 - val_loss: 0.5960 - val_acc: 0.7986\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.4032 - acc: 0.8562 - val_loss: 0.5952 - val_acc: 0.7981\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 20s 497us/step - loss: 0.3905 - acc: 0.8630 - val_loss: 0.6092 - val_acc: 0.7971\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3835 - acc: 0.8640 - val_loss: 0.5926 - val_acc: 0.7999\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.3738 - acc: 0.8663 - val_loss: 0.5996 - val_acc: 0.7981\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.3681 - acc: 0.8688 - val_loss: 0.5878 - val_acc: 0.8030\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.3533 - acc: 0.8755 - val_loss: 0.5998 - val_acc: 0.8055\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3494 - acc: 0.8750 - val_loss: 0.6064 - val_acc: 0.8032\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3428 - acc: 0.8777 - val_loss: 0.6039 - val_acc: 0.8030\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.3322 - acc: 0.8813 - val_loss: 0.6188 - val_acc: 0.8024\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.3269 - acc: 0.8831 - val_loss: 0.6040 - val_acc: 0.8038\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3221 - acc: 0.8848 - val_loss: 0.6094 - val_acc: 0.8012\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3139 - acc: 0.8884 - val_loss: 0.6048 - val_acc: 0.8044\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.3043 - acc: 0.8896 - val_loss: 0.6161 - val_acc: 0.8065\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 21s 519us/step - loss: 0.3008 - acc: 0.8927 - val_loss: 0.6180 - val_acc: 0.8045\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.2883 - acc: 0.8968 - val_loss: 0.6028 - val_acc: 0.8081\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.2865 - acc: 0.8974 - val_loss: 0.6070 - val_acc: 0.8072\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 21s 520us/step - loss: 0.2773 - acc: 0.9017 - val_loss: 0.6309 - val_acc: 0.8029\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 21s 519us/step - loss: 0.2722 - acc: 0.9031 - val_loss: 0.6257 - val_acc: 0.8080\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.2670 - acc: 0.9050 - val_loss: 0.6366 - val_acc: 0.8051\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 21s 519us/step - loss: 0.2614 - acc: 0.9052 - val_loss: 0.6327 - val_acc: 0.8051\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.2583 - acc: 0.9080 - val_loss: 0.6248 - val_acc: 0.8065\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.2535 - acc: 0.9086 - val_loss: 0.6308 - val_acc: 0.8035\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 21s 520us/step - loss: 0.2427 - acc: 0.9155 - val_loss: 0.6281 - val_acc: 0.8098\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.2394 - acc: 0.9122 - val_loss: 0.6399 - val_acc: 0.8051\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.2380 - acc: 0.9150 - val_loss: 0.6354 - val_acc: 0.8102\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.2268 - acc: 0.9192 - val_loss: 0.6515 - val_acc: 0.8078\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.2274 - acc: 0.9188 - val_loss: 0.6337 - val_acc: 0.8090\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.2219 - acc: 0.9214 - val_loss: 0.6641 - val_acc: 0.8019\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 21s 520us/step - loss: 0.2184 - acc: 0.9223 - val_loss: 0.6582 - val_acc: 0.8085\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.2100 - acc: 0.9255 - val_loss: 0.6602 - val_acc: 0.8075\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.2129 - acc: 0.9252 - val_loss: 0.6594 - val_acc: 0.8098\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.1985 - acc: 0.9299 - val_loss: 0.6793 - val_acc: 0.8058\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.2017 - acc: 0.9282 - val_loss: 0.6529 - val_acc: 0.8111\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 22s 541us/step - loss: 0.1948 - acc: 0.9302 - val_loss: 0.6760 - val_acc: 0.8066\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 22s 542us/step - loss: 0.1961 - acc: 0.9295 - val_loss: 0.6591 - val_acc: 0.8092\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 22s 538us/step - loss: 0.1885 - acc: 0.9331 - val_loss: 0.6693 - val_acc: 0.8107\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 21s 536us/step - loss: 0.1891 - acc: 0.9327 - val_loss: 0.6873 - val_acc: 0.8085\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 21s 536us/step - loss: 0.1888 - acc: 0.9331 - val_loss: 0.6787 - val_acc: 0.8121\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 22s 538us/step - loss: 0.1855 - acc: 0.9334 - val_loss: 0.6590 - val_acc: 0.8104\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 20s 508us/step - loss: 0.1795 - acc: 0.9355 - val_loss: 0.6729 - val_acc: 0.8126\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.1785 - acc: 0.9360 - val_loss: 0.6842 - val_acc: 0.8106\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.1727 - acc: 0.9377 - val_loss: 0.7004 - val_acc: 0.8097\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.1726 - acc: 0.9372 - val_loss: 0.6953 - val_acc: 0.8096\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.1672 - acc: 0.9405 - val_loss: 0.6846 - val_acc: 0.8115\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.1651 - acc: 0.9416 - val_loss: 0.6880 - val_acc: 0.8145\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1673 - acc: 0.9403 - val_loss: 0.6728 - val_acc: 0.8155\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1579 - acc: 0.9437 - val_loss: 0.7060 - val_acc: 0.8075\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1592 - acc: 0.9433 - val_loss: 0.6889 - val_acc: 0.8152\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1553 - acc: 0.9445 - val_loss: 0.7030 - val_acc: 0.8128\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1530 - acc: 0.9451 - val_loss: 0.7095 - val_acc: 0.8092\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1531 - acc: 0.9461 - val_loss: 0.6928 - val_acc: 0.8145\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1530 - acc: 0.9457 - val_loss: 0.7223 - val_acc: 0.8115\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1506 - acc: 0.9453 - val_loss: 0.7165 - val_acc: 0.8116\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 21s 527us/step - loss: 0.1455 - acc: 0.9482 - val_loss: 0.7087 - val_acc: 0.8151\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.1460 - acc: 0.9491 - val_loss: 0.7059 - val_acc: 0.8120\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1395 - acc: 0.9506 - val_loss: 0.7089 - val_acc: 0.8124\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 21s 528us/step - loss: 0.1422 - acc: 0.9495 - val_loss: 0.7464 - val_acc: 0.8112\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1393 - acc: 0.9508 - val_loss: 0.7525 - val_acc: 0.8069\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1339 - acc: 0.9528 - val_loss: 0.7299 - val_acc: 0.8127\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 20s 503us/step - loss: 0.1342 - acc: 0.9529 - val_loss: 0.7276 - val_acc: 0.8155\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 21s 526us/step - loss: 0.1352 - acc: 0.9523 - val_loss: 0.7214 - val_acc: 0.8157\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1280 - acc: 0.9549 - val_loss: 0.7329 - val_acc: 0.8137\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 20s 499us/step - loss: 0.1298 - acc: 0.9543 - val_loss: 0.7448 - val_acc: 0.8110\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 21s 520us/step - loss: 0.1282 - acc: 0.9543 - val_loss: 0.7265 - val_acc: 0.8103\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.1280 - acc: 0.9556 - val_loss: 0.7415 - val_acc: 0.8165\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.1307 - acc: 0.9525 - val_loss: 0.7226 - val_acc: 0.8122\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.1222 - acc: 0.9568 - val_loss: 0.7438 - val_acc: 0.8099\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.1233 - acc: 0.9558 - val_loss: 0.7302 - val_acc: 0.8164\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.1177 - acc: 0.9589 - val_loss: 0.7682 - val_acc: 0.8106\n",
            "Test loss: 0.768152096414566\n",
            "Test accuracy: 0.8106\n",
            "[0.768152096414566, 0.8106]\n",
            "{'val_loss': [0.8857792279243469, 0.8818993198394776, 0.8553910651206971, 0.7940901525497437, 0.7876400099754334, 0.7674114816665649, 0.7378555423736572, 0.7315167823791504, 0.7272142900943757, 0.7367092975616455, 0.6841654475212097, 0.6844283845901489, 0.6627507382392883, 0.6590142029762268, 0.660675356388092, 0.6483041640281677, 0.6402534780025482, 0.6278173401355743, 0.6242489591598511, 0.619456764125824, 0.6198321301937103, 0.6071817338466644, 0.6164935804367065, 0.614001221370697, 0.6103619738578796, 0.6004400125026703, 0.6073198053359985, 0.6191600027561188, 0.6023752007961273, 0.5980257582187652, 0.5959704253196716, 0.5952222021102905, 0.6091738029956818, 0.5925919283866883, 0.5995934686660767, 0.5878181163311005, 0.5997542159557343, 0.6064029286384582, 0.6038997961997986, 0.6188215387821198, 0.6040042883396148, 0.6093622737884522, 0.6047929759025574, 0.6161363707065582, 0.6180476491928101, 0.6028418601512909, 0.6070233067035675, 0.6308759918689728, 0.6257001516580581, 0.636605122423172, 0.632717208814621, 0.6247770728588105, 0.6308186961650848, 0.6281279396057129, 0.6399166486263275, 0.6353851925373077, 0.6515102303981781, 0.6337068574428558, 0.6640614158153534, 0.6582410512685776, 0.6601949983119965, 0.6593740404605866, 0.6792915814876557, 0.6528586420059204, 0.6759942174911499, 0.6591437787055969, 0.6693314484119415, 0.6872657601118087, 0.6787325427293778, 0.6590430030584336, 0.6729121997356414, 0.684213110256195, 0.7003575009346008, 0.6953345523834229, 0.6845756073951721, 0.6879687790870667, 0.6728297231197358, 0.7059685455799103, 0.6889027903556824, 0.7030023282289505, 0.7094842954874039, 0.6927543574810028, 0.7223468908786773, 0.7165304157018662, 0.7087258616924286, 0.7059067015647889, 0.7088692922353744, 0.7463542673826218, 0.7525265167713165, 0.7298510468959808, 0.7275725782155991, 0.7213596566200257, 0.7329445012569428, 0.7447774307250976, 0.7265081455230713, 0.7414578179359436, 0.7225946840763092, 0.7438237302541733, 0.7301909734010696, 0.768152096414566], 'val_acc': [0.6915, 0.687, 0.6938, 0.7233, 0.7271, 0.7309, 0.7444, 0.7479, 0.7457, 0.7434, 0.7586, 0.7648, 0.7688, 0.7667, 0.7706, 0.7742, 0.7767, 0.7827, 0.7837, 0.7878, 0.7816, 0.7931, 0.7902, 0.7894, 0.7906, 0.7937, 0.7931, 0.79, 0.796, 0.7987, 0.7986, 0.7981, 0.7971, 0.7999, 0.7981, 0.803, 0.8055, 0.8032, 0.803, 0.8024, 0.8038, 0.8012, 0.8044, 0.8065, 0.8045, 0.8081, 0.8072, 0.8029, 0.808, 0.8051, 0.8051, 0.8065, 0.8035, 0.8098, 0.8051, 0.8102, 0.8078, 0.809, 0.8019, 0.8085, 0.8075, 0.8098, 0.8058, 0.8111, 0.8066, 0.8092, 0.8107, 0.8085, 0.8121, 0.8104, 0.8126, 0.8106, 0.8097, 0.8096, 0.8115, 0.8145, 0.8155, 0.8075, 0.8152, 0.8128, 0.8092, 0.8145, 0.8115, 0.8116, 0.8151, 0.812, 0.8124, 0.8112, 0.8069, 0.8127, 0.8155, 0.8157, 0.8137, 0.811, 0.8103, 0.8165, 0.8122, 0.8099, 0.8164, 0.8106], 'loss': [0.9784185500621796, 0.9337169932365418, 0.8969860766887665, 0.8662456057786941, 0.8342892889261245, 0.8056877251386643, 0.7760901657581329, 0.7493361937522888, 0.734259850692749, 0.7068616140723228, 0.6928193370342255, 0.6697060663700104, 0.6501030610084534, 0.6310079966783524, 0.620509916985035, 0.597054476583004, 0.5867759262442589, 0.5740215508699417, 0.555838736987114, 0.5438323393344879, 0.5260497953534127, 0.5158206040382385, 0.5028917845606804, 0.4928680261552334, 0.478310488319397, 0.4652876822710037, 0.45553977147340774, 0.44206106677055357, 0.4300574010372162, 0.42495465846657754, 0.4128338458776474, 0.4032432951807976, 0.39045852242708207, 0.38354856252074243, 0.3738321047842503, 0.368124832162261, 0.3532599644124508, 0.34943605422973634, 0.34278537232279777, 0.33219211412370203, 0.32691665645837786, 0.32213091434240343, 0.31391630789637565, 0.3043242897450924, 0.30076716749370097, 0.28825657443404196, 0.2864868213921785, 0.2773099092692137, 0.2721687691181898, 0.26697945952415464, 0.26142311920821665, 0.2582781024485826, 0.25347420239597557, 0.24271334831118585, 0.23944216770380736, 0.2380244208574295, 0.2268035765081644, 0.22742253544032573, 0.22190670990794897, 0.21843946789205074, 0.20998068711012602, 0.212942332790792, 0.19854147796630858, 0.201720537596941, 0.19477131189107894, 0.19612096695974468, 0.1885216503933072, 0.18914856659322976, 0.18879976783394814, 0.185501908262074, 0.17946986915841698, 0.17845829368159175, 0.1727191360272467, 0.17263037397116424, 0.16723348112255335, 0.16507407600209117, 0.16725265779495238, 0.15787860720604657, 0.1592316551566124, 0.1552799476839602, 0.1529840158082545, 0.153135503257066, 0.15299535108208656, 0.15063136944696306, 0.1455209629252553, 0.14596909530460833, 0.1394858677819371, 0.14219397950991988, 0.13929815800860523, 0.13392973243482412, 0.13417403301596642, 0.1351757920317352, 0.12800769094750286, 0.12982929201349616, 0.12819588313810526, 0.12797930916100742, 0.1307408376581967, 0.12215597193092108, 0.12327009559646249, 0.11765734997950494], 'acc': [0.6544, 0.6691, 0.68385, 0.69585, 0.707125, 0.716425, 0.72765, 0.735025, 0.741225, 0.7536, 0.75705, 0.764725, 0.77165, 0.77725, 0.7832, 0.78975, 0.79215, 0.798375, 0.8036, 0.807875, 0.814925, 0.818175, 0.8198, 0.824525, 0.830275, 0.83585, 0.838775, 0.84375, 0.848525, 0.8491, 0.855225, 0.856225, 0.863025, 0.863975, 0.8663, 0.868775, 0.8755, 0.875, 0.877725, 0.881325, 0.883125, 0.88485, 0.88845, 0.889575, 0.89265, 0.896775, 0.897375, 0.9017, 0.9031, 0.905, 0.9052, 0.907975, 0.908575, 0.9155, 0.912175, 0.915025, 0.919225, 0.918775, 0.921425, 0.922325, 0.925525, 0.9252, 0.929875, 0.928175, 0.9302, 0.929475, 0.933125, 0.932675, 0.933125, 0.9334, 0.93555, 0.93595, 0.937725, 0.937175, 0.940475, 0.94165, 0.94025, 0.943675, 0.94325, 0.94445, 0.945075, 0.946075, 0.9457, 0.9453, 0.94825, 0.949075, 0.950625, 0.94945, 0.950825, 0.952775, 0.9529, 0.95225, 0.954925, 0.9543, 0.95425, 0.955625, 0.952525, 0.956775, 0.955825, 0.958925]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss: 0.768152096414566\n",
            "validation accuracy: 0.8106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GTUKp9NaVlY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Second Architecture Training and Validation set"
      ]
    },
    {
      "metadata": {
        "id": "P9Nevunr29r3",
        "colab_type": "code",
        "outputId": "cdbc248a-32d1-48f0-a077-fab38130c5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4291
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 1.8855 - acc: 0.3043\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 398us/step - loss: 1.5958 - acc: 0.4142\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 395us/step - loss: 1.4893 - acc: 0.4567\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 395us/step - loss: 1.4152 - acc: 0.4924\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 401us/step - loss: 1.3536 - acc: 0.5155\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 390us/step - loss: 1.2935 - acc: 0.5368\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 400us/step - loss: 1.2447 - acc: 0.5569\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 389us/step - loss: 1.2116 - acc: 0.5689\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 399us/step - loss: 1.1667 - acc: 0.5860\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 391us/step - loss: 1.1388 - acc: 0.5963\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 17s 426us/step - loss: 1.0073 - acc: 0.6454 - val_loss: 0.9180 - val_acc: 0.6793\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.9616 - acc: 0.6612 - val_loss: 0.8823 - val_acc: 0.6913\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.9306 - acc: 0.6732 - val_loss: 0.8522 - val_acc: 0.7072\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.8938 - acc: 0.6863 - val_loss: 0.8398 - val_acc: 0.7112\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.8666 - acc: 0.6951 - val_loss: 0.8005 - val_acc: 0.7244\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.8419 - acc: 0.7038 - val_loss: 0.7887 - val_acc: 0.7290\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.8148 - acc: 0.7128 - val_loss: 0.7799 - val_acc: 0.7269\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.7880 - acc: 0.7203 - val_loss: 0.7603 - val_acc: 0.7357\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.7617 - acc: 0.7320 - val_loss: 0.7684 - val_acc: 0.7295\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.7427 - acc: 0.7389 - val_loss: 0.7307 - val_acc: 0.7501\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.7222 - acc: 0.7438 - val_loss: 0.7483 - val_acc: 0.7432\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.6991 - acc: 0.7533 - val_loss: 0.7175 - val_acc: 0.7511\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.6804 - acc: 0.7606 - val_loss: 0.7243 - val_acc: 0.7513\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.6620 - acc: 0.7685 - val_loss: 0.7064 - val_acc: 0.7571\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.6437 - acc: 0.7770 - val_loss: 0.6926 - val_acc: 0.7604\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 17s 415us/step - loss: 0.6244 - acc: 0.7812 - val_loss: 0.6836 - val_acc: 0.7638\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.6068 - acc: 0.7878 - val_loss: 0.6825 - val_acc: 0.7655\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.5872 - acc: 0.7935 - val_loss: 0.6963 - val_acc: 0.7656\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.5754 - acc: 0.7983 - val_loss: 0.6712 - val_acc: 0.7726\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 17s 415us/step - loss: 0.5553 - acc: 0.8051 - val_loss: 0.6843 - val_acc: 0.7679\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.5429 - acc: 0.8086 - val_loss: 0.6629 - val_acc: 0.7756\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.5299 - acc: 0.8121 - val_loss: 0.6453 - val_acc: 0.7782\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.5152 - acc: 0.8184 - val_loss: 0.6535 - val_acc: 0.7818\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.4969 - acc: 0.8242 - val_loss: 0.6605 - val_acc: 0.7784\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.4870 - acc: 0.8283 - val_loss: 0.6503 - val_acc: 0.7787\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.4769 - acc: 0.8303 - val_loss: 0.6451 - val_acc: 0.7811\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.4616 - acc: 0.8374 - val_loss: 0.6573 - val_acc: 0.7819\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.4480 - acc: 0.8404 - val_loss: 0.6409 - val_acc: 0.7842\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.4392 - acc: 0.8438 - val_loss: 0.6476 - val_acc: 0.7812\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.4254 - acc: 0.8477 - val_loss: 0.6527 - val_acc: 0.7812\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.4199 - acc: 0.8509 - val_loss: 0.6488 - val_acc: 0.7852\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.4101 - acc: 0.8537 - val_loss: 0.6430 - val_acc: 0.7859\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.3985 - acc: 0.8576 - val_loss: 0.6466 - val_acc: 0.7884\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.3844 - acc: 0.8630 - val_loss: 0.6720 - val_acc: 0.7821\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.3834 - acc: 0.8621 - val_loss: 0.6481 - val_acc: 0.7895\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.3677 - acc: 0.8690 - val_loss: 0.6468 - val_acc: 0.7909\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 17s 415us/step - loss: 0.3583 - acc: 0.8718 - val_loss: 0.6444 - val_acc: 0.7897\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 17s 415us/step - loss: 0.3533 - acc: 0.8758 - val_loss: 0.6520 - val_acc: 0.7899\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 17s 414us/step - loss: 0.3468 - acc: 0.8763 - val_loss: 0.6607 - val_acc: 0.7927\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.3357 - acc: 0.8798 - val_loss: 0.6621 - val_acc: 0.7927\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.3278 - acc: 0.8842 - val_loss: 0.6528 - val_acc: 0.7931\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.3228 - acc: 0.8845 - val_loss: 0.6465 - val_acc: 0.7944\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.3116 - acc: 0.8890 - val_loss: 0.6587 - val_acc: 0.7957\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.3075 - acc: 0.8908 - val_loss: 0.6611 - val_acc: 0.7949\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.2995 - acc: 0.8935 - val_loss: 0.6670 - val_acc: 0.7940\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2966 - acc: 0.8936 - val_loss: 0.6758 - val_acc: 0.7928\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2894 - acc: 0.8954 - val_loss: 0.6757 - val_acc: 0.7942\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2827 - acc: 0.8994 - val_loss: 0.6768 - val_acc: 0.7943\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2746 - acc: 0.9005 - val_loss: 0.6881 - val_acc: 0.7936\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.2727 - acc: 0.9041 - val_loss: 0.6705 - val_acc: 0.7968\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2662 - acc: 0.9038 - val_loss: 0.6757 - val_acc: 0.7961\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2627 - acc: 0.9068 - val_loss: 0.6798 - val_acc: 0.7972\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.2585 - acc: 0.9065 - val_loss: 0.6761 - val_acc: 0.7962\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.2539 - acc: 0.9095 - val_loss: 0.6871 - val_acc: 0.7949\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.2466 - acc: 0.9100 - val_loss: 0.6847 - val_acc: 0.8007\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2434 - acc: 0.9131 - val_loss: 0.7035 - val_acc: 0.7982\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.2423 - acc: 0.9119 - val_loss: 0.6827 - val_acc: 0.7958\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2357 - acc: 0.9169 - val_loss: 0.7237 - val_acc: 0.7914\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2316 - acc: 0.9185 - val_loss: 0.7031 - val_acc: 0.7945\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.2267 - acc: 0.9201 - val_loss: 0.7035 - val_acc: 0.7956\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2222 - acc: 0.9220 - val_loss: 0.7215 - val_acc: 0.7978\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.2233 - acc: 0.9192 - val_loss: 0.7088 - val_acc: 0.7966\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2172 - acc: 0.9218 - val_loss: 0.7021 - val_acc: 0.8013\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2153 - acc: 0.9240 - val_loss: 0.7133 - val_acc: 0.7974\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.2108 - acc: 0.9260 - val_loss: 0.7251 - val_acc: 0.7985\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.2117 - acc: 0.9250 - val_loss: 0.7153 - val_acc: 0.7938\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.2061 - acc: 0.9273 - val_loss: 0.7215 - val_acc: 0.7994\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.2019 - acc: 0.9277 - val_loss: 0.7092 - val_acc: 0.7981\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1988 - acc: 0.9298 - val_loss: 0.7831 - val_acc: 0.7912\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.2000 - acc: 0.9279 - val_loss: 0.7080 - val_acc: 0.7997\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 17s 416us/step - loss: 0.1959 - acc: 0.9304 - val_loss: 0.7113 - val_acc: 0.8009\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 17s 418us/step - loss: 0.1885 - acc: 0.9334 - val_loss: 0.7307 - val_acc: 0.7996\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 17s 419us/step - loss: 0.1867 - acc: 0.9338 - val_loss: 0.7306 - val_acc: 0.7993\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 0.1840 - acc: 0.9352 - val_loss: 0.7232 - val_acc: 0.8015\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1834 - acc: 0.9354 - val_loss: 0.7479 - val_acc: 0.7994\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1851 - acc: 0.9346 - val_loss: 0.7435 - val_acc: 0.7996\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1834 - acc: 0.9338 - val_loss: 0.7167 - val_acc: 0.8000\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1777 - acc: 0.9372 - val_loss: 0.7386 - val_acc: 0.7986\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1816 - acc: 0.9355 - val_loss: 0.7432 - val_acc: 0.7988\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1693 - acc: 0.9409 - val_loss: 0.7331 - val_acc: 0.7978\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 0.1675 - acc: 0.9413 - val_loss: 0.7575 - val_acc: 0.7965\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1727 - acc: 0.9396 - val_loss: 0.7325 - val_acc: 0.8004\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1705 - acc: 0.9403 - val_loss: 0.7476 - val_acc: 0.7970\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 0.1682 - acc: 0.9397 - val_loss: 0.7405 - val_acc: 0.7988\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1661 - acc: 0.9412 - val_loss: 0.7300 - val_acc: 0.8004\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.1631 - acc: 0.9418 - val_loss: 0.7408 - val_acc: 0.7940\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 0.1625 - acc: 0.9415 - val_loss: 0.7468 - val_acc: 0.8028\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.1599 - acc: 0.9437 - val_loss: 0.7497 - val_acc: 0.7970\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 0.1598 - acc: 0.9436 - val_loss: 0.7431 - val_acc: 0.8045\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1552 - acc: 0.9448 - val_loss: 0.7638 - val_acc: 0.8010\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 0.1570 - acc: 0.9445 - val_loss: 0.7615 - val_acc: 0.7989\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1521 - acc: 0.9455 - val_loss: 0.7724 - val_acc: 0.7994\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1529 - acc: 0.9453 - val_loss: 0.7727 - val_acc: 0.8003\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 0.1476 - acc: 0.9482 - val_loss: 0.7802 - val_acc: 0.7990\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1503 - acc: 0.9475 - val_loss: 0.7855 - val_acc: 0.7992\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1466 - acc: 0.9489 - val_loss: 0.7630 - val_acc: 0.7973\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1434 - acc: 0.9490 - val_loss: 0.7706 - val_acc: 0.8012\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1454 - acc: 0.9499 - val_loss: 0.7723 - val_acc: 0.7978\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 0.1443 - acc: 0.9487 - val_loss: 0.7875 - val_acc: 0.8000\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 0.1401 - acc: 0.9502 - val_loss: 0.7712 - val_acc: 0.8007\n",
            "Test loss: 0.7711876882076263\n",
            "Test accuracy: 0.8007\n",
            "[0.7711876882076263, 0.8007]\n",
            "{'val_loss': [0.9179880935668945, 0.8823024395942688, 0.852248657989502, 0.8398222885131836, 0.8004704404830932, 0.7886865027427673, 0.7799241687774658, 0.7602811529159546, 0.7684068767547607, 0.7306667671203614, 0.7482647553443909, 0.7174720165252686, 0.7242701746940613, 0.706387821483612, 0.6926254027366638, 0.6835712779045104, 0.6825375385284423, 0.6963025373458862, 0.6711826574325561, 0.684285520362854, 0.6629228219985962, 0.6453241095542908, 0.6534608670234681, 0.660464456987381, 0.6502678595542908, 0.645090996837616, 0.6573140291213989, 0.6408789336204529, 0.6476146115779877, 0.6526702179431916, 0.6487738558292389, 0.6429963854789734, 0.6466148996353149, 0.6720128848075867, 0.6481414375782013, 0.6468456752300262, 0.644441073179245, 0.6520436485767365, 0.660656819486618, 0.6621122214794158, 0.6527614536762237, 0.6464972049713135, 0.658685073518753, 0.6611428988933563, 0.6669798907756805, 0.6757937694072723, 0.6757347594738007, 0.6768238026618958, 0.68810430560112, 0.6705218738555908, 0.675749478340149, 0.679838375377655, 0.6760777853965759, 0.6871327313899994, 0.6846803432941436, 0.7035197647094726, 0.6827346652030944, 0.7237190457820892, 0.7031438200950623, 0.7035405549526215, 0.7214929347038269, 0.7087676750183105, 0.702127093410492, 0.7133054197311401, 0.7251010043144226, 0.7153183163166046, 0.7214977217197418, 0.7092003288269043, 0.7831453510761262, 0.7079885263442993, 0.7112892446041107, 0.7307138144731522, 0.7305714492559433, 0.7232203206539154, 0.7478866488933563, 0.7434505640506744, 0.7167325106620789, 0.7385988958120346, 0.743182964515686, 0.7331142838478089, 0.7574698085784912, 0.7325130745649338, 0.7475510052204132, 0.7404804614543915, 0.7300469470739365, 0.7407911445617675, 0.7467936269283295, 0.7496749830245971, 0.7430906648159027, 0.7637945375919342, 0.7614756042480468, 0.7723613463878631, 0.7727469895362854, 0.7802078540802002, 0.7855276891708374, 0.763001500248909, 0.7705797881126404, 0.7723287324905396, 0.7875093029975891, 0.7711876882076263], 'val_acc': [0.6793, 0.6913, 0.7072, 0.7112, 0.7244, 0.729, 0.7269, 0.7357, 0.7295, 0.7501, 0.7432, 0.7511, 0.7513, 0.7571, 0.7604, 0.7638, 0.7655, 0.7656, 0.7726, 0.7679, 0.7756, 0.7782, 0.7818, 0.7784, 0.7787, 0.7811, 0.7819, 0.7842, 0.7812, 0.7812, 0.7852, 0.7859, 0.7884, 0.7821, 0.7895, 0.7909, 0.7897, 0.7899, 0.7927, 0.7927, 0.7931, 0.7944, 0.7957, 0.7949, 0.794, 0.7928, 0.7942, 0.7943, 0.7936, 0.7968, 0.7961, 0.7972, 0.7962, 0.7949, 0.8007, 0.7982, 0.7958, 0.7914, 0.7945, 0.7956, 0.7978, 0.7966, 0.8013, 0.7974, 0.7985, 0.7938, 0.7994, 0.7981, 0.7912, 0.7997, 0.8009, 0.7996, 0.7993, 0.8015, 0.7994, 0.7996, 0.8, 0.7986, 0.7988, 0.7978, 0.7965, 0.8004, 0.797, 0.7988, 0.8004, 0.794, 0.8028, 0.797, 0.8045, 0.801, 0.7989, 0.7994, 0.8003, 0.799, 0.7992, 0.7973, 0.8012, 0.7978, 0.8, 0.8007], 'loss': [1.007303370666504, 0.9616268367052079, 0.9306104944705963, 0.8938147038698196, 0.8666171549081803, 0.8419218834161758, 0.8148407918453217, 0.7880320479631424, 0.7616908253908158, 0.742652610039711, 0.7222478042602539, 0.6990597486495972, 0.6804051391124726, 0.6620181802988052, 0.6436906961083412, 0.6244015046477318, 0.6067502555608749, 0.5872140503287315, 0.5753782426834106, 0.5552652939558029, 0.54285155762434, 0.5299377276182174, 0.5152375085115433, 0.4969099497079849, 0.48699882715940473, 0.47686044791936877, 0.46163785313367844, 0.4479701589524746, 0.43922154833078386, 0.42540470883250237, 0.41989759747982025, 0.4100659754157066, 0.39852699275016784, 0.38436108971238137, 0.3834112229585648, 0.3677424048483372, 0.358327430665493, 0.3532743106424808, 0.3468289076566696, 0.3357140051484108, 0.3278067498445511, 0.32283307233452796, 0.3116075966447592, 0.3074575143456459, 0.29951506293416025, 0.2966280152916908, 0.2893764464467764, 0.282748038187623, 0.2745634837239981, 0.2727144392192364, 0.2662209470808506, 0.2627302343428135, 0.2585276713863015, 0.2539130836248398, 0.24662995224893094, 0.24338375614881516, 0.24230151899456978, 0.23572573441267014, 0.23159033905863763, 0.22673965379297734, 0.22223215642869473, 0.22333382339179517, 0.21719468081146479, 0.21534365177303552, 0.21075906422287224, 0.21170659870505332, 0.20606928380429745, 0.20187697746455668, 0.1987843468144536, 0.20003978756964208, 0.19585277900546788, 0.18845336645543576, 0.1866674492880702, 0.18403528665304184, 0.183370532207191, 0.1851047610014677, 0.18336555744484068, 0.17770937202945353, 0.18164763250350952, 0.16925870904028414, 0.16752971679493786, 0.17274630802124738, 0.17053291674628854, 0.16824194024279715, 0.16606866288408637, 0.16307159929051995, 0.1624807219401002, 0.15994046089500188, 0.15983719381839037, 0.15524778651744128, 0.15702781757041812, 0.15210661389157176, 0.15294885768294333, 0.1476466175235808, 0.150346735907346, 0.14657549796029926, 0.14337340109236538, 0.14544660982005297, 0.14432068754881622, 0.1401045288681984], 'acc': [0.64545, 0.661225, 0.673225, 0.6863, 0.695075, 0.703775, 0.71285, 0.720275, 0.731975, 0.738875, 0.7438, 0.7533, 0.7606, 0.768475, 0.777025, 0.78115, 0.787825, 0.79355, 0.798325, 0.8051, 0.808575, 0.8121, 0.8184, 0.824225, 0.828325, 0.8303, 0.8374, 0.840425, 0.8438, 0.84775, 0.8509, 0.853675, 0.8576, 0.86305, 0.862075, 0.86905, 0.871775, 0.875825, 0.876325, 0.879775, 0.884175, 0.8845, 0.88895, 0.8908, 0.8935, 0.89365, 0.8954, 0.89945, 0.90045, 0.904075, 0.9038, 0.906825, 0.9065, 0.909475, 0.909975, 0.9131, 0.91195, 0.9169, 0.918475, 0.920075, 0.922025, 0.91925, 0.921825, 0.923975, 0.925975, 0.925, 0.92725, 0.927675, 0.9298, 0.927875, 0.930425, 0.933375, 0.93385, 0.9352, 0.935375, 0.93465, 0.933825, 0.937175, 0.935475, 0.9409, 0.941275, 0.939575, 0.940325, 0.9397, 0.9412, 0.94185, 0.941525, 0.943725, 0.9436, 0.9448, 0.9445, 0.945475, 0.945325, 0.948175, 0.9475, 0.948875, 0.948975, 0.94995, 0.948675, 0.950225]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUKiLiIj4CYW6iIiIn1Coi4iI+In/D/GYME6mZvCeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss: 0.7711876882076263\n",
            "validation accuracy: 0.8007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLFCNCh4Vqm2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Third Architecture Training and Validation set"
      ]
    },
    {
      "metadata": {
        "id": "WDyj9V7K25_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4291
        },
        "outputId": "1ac3a710-e187-4995-9a14-42afba54745e"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_tra.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 1.8618 - acc: 0.3263\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 276us/step - loss: 1.6201 - acc: 0.4099\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 268us/step - loss: 1.5348 - acc: 0.4429\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 268us/step - loss: 1.4765 - acc: 0.4663\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 268us/step - loss: 1.4343 - acc: 0.4805\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 269us/step - loss: 1.4077 - acc: 0.4938\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 275us/step - loss: 1.3752 - acc: 0.5055\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 268us/step - loss: 1.3447 - acc: 0.5182\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 270us/step - loss: 1.3213 - acc: 0.5284\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 11s 269us/step - loss: 1.2956 - acc: 0.5373\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 1.1733 - acc: 0.5811 - val_loss: 1.2227 - val_acc: 0.5682\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 1.1353 - acc: 0.5967 - val_loss: 1.1438 - val_acc: 0.5991\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 1.1042 - acc: 0.6085 - val_loss: 1.1295 - val_acc: 0.6025\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 1.0778 - acc: 0.6203 - val_loss: 1.1211 - val_acc: 0.6027\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 1.0512 - acc: 0.6311 - val_loss: 1.1023 - val_acc: 0.6159\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 1.0299 - acc: 0.6386 - val_loss: 1.0756 - val_acc: 0.6249\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 1.0091 - acc: 0.6459 - val_loss: 1.0826 - val_acc: 0.6202\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.9881 - acc: 0.6545 - val_loss: 1.0411 - val_acc: 0.6385\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.9695 - acc: 0.6612 - val_loss: 1.0270 - val_acc: 0.6425\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.9503 - acc: 0.6664 - val_loss: 1.0623 - val_acc: 0.6267\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.9336 - acc: 0.6744 - val_loss: 1.0229 - val_acc: 0.6441\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.9178 - acc: 0.6808 - val_loss: 1.0121 - val_acc: 0.6457\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.9015 - acc: 0.6855 - val_loss: 0.9960 - val_acc: 0.6530\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.8826 - acc: 0.6928 - val_loss: 0.9863 - val_acc: 0.6528\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.8695 - acc: 0.6968 - val_loss: 0.9806 - val_acc: 0.6581\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.8537 - acc: 0.7048 - val_loss: 0.9966 - val_acc: 0.6527\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.8394 - acc: 0.7081 - val_loss: 0.9955 - val_acc: 0.6556\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.8253 - acc: 0.7147 - val_loss: 0.9615 - val_acc: 0.6678\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.8112 - acc: 0.7186 - val_loss: 0.9651 - val_acc: 0.6659\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.7997 - acc: 0.7233 - val_loss: 0.9659 - val_acc: 0.6606\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.7867 - acc: 0.7283 - val_loss: 0.9464 - val_acc: 0.6705\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.7738 - acc: 0.7332 - val_loss: 0.9556 - val_acc: 0.6679\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.7611 - acc: 0.7373 - val_loss: 0.9509 - val_acc: 0.6717\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.7490 - acc: 0.7417 - val_loss: 0.9656 - val_acc: 0.6660\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.7366 - acc: 0.7459 - val_loss: 0.9579 - val_acc: 0.6681\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.7233 - acc: 0.7515 - val_loss: 0.9601 - val_acc: 0.6721\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.7116 - acc: 0.7550 - val_loss: 0.9311 - val_acc: 0.6791\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.6993 - acc: 0.7590 - val_loss: 0.9529 - val_acc: 0.6764\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.6867 - acc: 0.7650 - val_loss: 0.9396 - val_acc: 0.6800\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.6764 - acc: 0.7679 - val_loss: 0.9609 - val_acc: 0.6717\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.6669 - acc: 0.7709 - val_loss: 0.9489 - val_acc: 0.6780\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.6545 - acc: 0.7764 - val_loss: 0.9580 - val_acc: 0.6764\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.6437 - acc: 0.7818 - val_loss: 0.9626 - val_acc: 0.6743\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.6354 - acc: 0.7833 - val_loss: 0.9317 - val_acc: 0.6872\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.6223 - acc: 0.7870 - val_loss: 0.9567 - val_acc: 0.6810\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.6140 - acc: 0.7895 - val_loss: 0.9681 - val_acc: 0.6800\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.6009 - acc: 0.7933 - val_loss: 0.9449 - val_acc: 0.6866\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.5923 - acc: 0.7969 - val_loss: 0.9388 - val_acc: 0.6904\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.5832 - acc: 0.8001 - val_loss: 0.9416 - val_acc: 0.6875\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.5730 - acc: 0.8044 - val_loss: 0.9640 - val_acc: 0.6832\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.5620 - acc: 0.8083 - val_loss: 0.9757 - val_acc: 0.6802\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.5520 - acc: 0.8113 - val_loss: 0.9725 - val_acc: 0.6879\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.5442 - acc: 0.8145 - val_loss: 0.9603 - val_acc: 0.6888\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.5319 - acc: 0.8174 - val_loss: 0.9673 - val_acc: 0.6864\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.5253 - acc: 0.8202 - val_loss: 0.9625 - val_acc: 0.6859\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.5137 - acc: 0.8275 - val_loss: 0.9726 - val_acc: 0.6851\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.5050 - acc: 0.8303 - val_loss: 0.9777 - val_acc: 0.6852\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.4926 - acc: 0.8337 - val_loss: 0.9606 - val_acc: 0.6960\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.4848 - acc: 0.8344 - val_loss: 0.9801 - val_acc: 0.6894\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.4769 - acc: 0.8380 - val_loss: 0.9923 - val_acc: 0.6890\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.4653 - acc: 0.8420 - val_loss: 1.0066 - val_acc: 0.6893\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.4600 - acc: 0.8467 - val_loss: 1.0258 - val_acc: 0.6812\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.4477 - acc: 0.8478 - val_loss: 1.0143 - val_acc: 0.6855\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.4423 - acc: 0.8509 - val_loss: 1.0342 - val_acc: 0.6839\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.4283 - acc: 0.8562 - val_loss: 1.0207 - val_acc: 0.6903\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.4246 - acc: 0.8572 - val_loss: 1.0293 - val_acc: 0.6888\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.4123 - acc: 0.8609 - val_loss: 1.0407 - val_acc: 0.6880\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.4040 - acc: 0.8667 - val_loss: 1.0484 - val_acc: 0.6860\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.3969 - acc: 0.8673 - val_loss: 1.0548 - val_acc: 0.6864\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.3860 - acc: 0.8726 - val_loss: 1.1002 - val_acc: 0.6793\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.3794 - acc: 0.8729 - val_loss: 1.0683 - val_acc: 0.6874\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3710 - acc: 0.8766 - val_loss: 1.0824 - val_acc: 0.6862\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.3613 - acc: 0.8799 - val_loss: 1.0927 - val_acc: 0.6834\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3529 - acc: 0.8844 - val_loss: 1.1249 - val_acc: 0.6838\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.3441 - acc: 0.8861 - val_loss: 1.1384 - val_acc: 0.6789\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3352 - acc: 0.8888 - val_loss: 1.1654 - val_acc: 0.6777\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.3302 - acc: 0.8917 - val_loss: 1.1557 - val_acc: 0.6787\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3210 - acc: 0.8952 - val_loss: 1.1399 - val_acc: 0.6888\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3141 - acc: 0.8979 - val_loss: 1.1551 - val_acc: 0.6820\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.3047 - acc: 0.9000 - val_loss: 1.1633 - val_acc: 0.6841\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.2955 - acc: 0.9047 - val_loss: 1.1818 - val_acc: 0.6849\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.2871 - acc: 0.9060 - val_loss: 1.2302 - val_acc: 0.6742\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2822 - acc: 0.9090 - val_loss: 1.2360 - val_acc: 0.6826\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2728 - acc: 0.9129 - val_loss: 1.2512 - val_acc: 0.6759\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2656 - acc: 0.9141 - val_loss: 1.2607 - val_acc: 0.6793\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.2608 - acc: 0.9176 - val_loss: 1.2626 - val_acc: 0.6830\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.2528 - acc: 0.9184 - val_loss: 1.2817 - val_acc: 0.6786\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2428 - acc: 0.9230 - val_loss: 1.2895 - val_acc: 0.6805\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 0.2364 - acc: 0.9234 - val_loss: 1.3119 - val_acc: 0.6781\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2299 - acc: 0.9291 - val_loss: 1.3460 - val_acc: 0.6766\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2192 - acc: 0.9326 - val_loss: 1.3498 - val_acc: 0.6745\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2155 - acc: 0.9323 - val_loss: 1.3718 - val_acc: 0.6735\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2070 - acc: 0.9365 - val_loss: 1.4005 - val_acc: 0.6729\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.2002 - acc: 0.9386 - val_loss: 1.3919 - val_acc: 0.6786\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 0.1954 - acc: 0.9400 - val_loss: 1.4176 - val_acc: 0.6740\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1871 - acc: 0.9433 - val_loss: 1.4483 - val_acc: 0.6718\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1803 - acc: 0.9460 - val_loss: 1.4465 - val_acc: 0.6765\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1762 - acc: 0.9466 - val_loss: 1.4845 - val_acc: 0.6732\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1690 - acc: 0.9506 - val_loss: 1.4882 - val_acc: 0.6768\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1620 - acc: 0.9523 - val_loss: 1.5220 - val_acc: 0.6760\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1575 - acc: 0.9540 - val_loss: 1.5248 - val_acc: 0.6731\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1509 - acc: 0.9561 - val_loss: 1.5447 - val_acc: 0.6770\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1459 - acc: 0.9583 - val_loss: 1.5891 - val_acc: 0.6761\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1420 - acc: 0.9592 - val_loss: 1.5888 - val_acc: 0.6758\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1338 - acc: 0.9634 - val_loss: 1.6026 - val_acc: 0.6745\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1319 - acc: 0.9630 - val_loss: 1.6419 - val_acc: 0.6754\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1213 - acc: 0.9667 - val_loss: 1.6746 - val_acc: 0.6701\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1191 - acc: 0.9677 - val_loss: 1.6651 - val_acc: 0.6723\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1134 - acc: 0.9692 - val_loss: 1.7628 - val_acc: 0.6637\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 12s 291us/step - loss: 0.1080 - acc: 0.9719 - val_loss: 1.7077 - val_acc: 0.6749\n",
            "Test loss: 1.7077101719856262\n",
            "Test accuracy: 0.6749\n",
            "[1.7077101719856262, 0.6749]\n",
            "{'val_loss': [1.2227438940048219, 1.1437814123153687, 1.1295428913116454, 1.1210530126571656, 1.1022940576553344, 1.0755840119361877, 1.0825694620132447, 1.0411300941467285, 1.0270128768920899, 1.0623085460662842, 1.0229461255073546, 1.0120899667739869, 0.99604397315979, 0.986322048664093, 0.980603818321228, 0.9965705530166626, 0.995549622631073, 0.9615398243904114, 0.9650988482475281, 0.965931593799591, 0.9464422275543213, 0.9555604089736939, 0.9508702036857605, 0.9655828628540039, 0.9578576076507568, 0.9600800000190735, 0.9311459153175354, 0.9528600858688354, 0.9395626572608948, 0.9609209228515625, 0.9489069726943969, 0.9579635332107544, 0.9625997367858887, 0.9317436252593995, 0.9566644652366638, 0.9680607275009155, 0.9448710472106934, 0.9388021795272827, 0.941637718296051, 0.9640068616867066, 0.9757440635681153, 0.9725319039344787, 0.9603326501846313, 0.9672661373138428, 0.9624755962371826, 0.9726101274490356, 0.977749767780304, 0.9605849390983582, 0.9801100212097168, 0.9922721568107605, 1.006630014896393, 1.0258321849822998, 1.0143087812423706, 1.0342031588554383, 1.0207201310157776, 1.0292950734138488, 1.040690792274475, 1.0483786467552185, 1.0548408876419066, 1.1001940443992615, 1.0682988089561463, 1.0824399291992188, 1.0926942304611207, 1.1249104207992553, 1.1384152875900269, 1.1654107957839965, 1.1556913840293885, 1.139879821395874, 1.1551113598823548, 1.1632546602249145, 1.1818006191253663, 1.2301888080596923, 1.235967874622345, 1.2512026894569397, 1.260684507369995, 1.2625740067481994, 1.2817302382469178, 1.2894882982254028, 1.3119176067352294, 1.3459918148994445, 1.3497949836730958, 1.3717746201515197, 1.4005338163375856, 1.3919183127403258, 1.417615854024887, 1.4482695817947389, 1.4464514617919921, 1.4844685991287232, 1.4881961932182313, 1.5220131038665772, 1.524845575428009, 1.5447347577095032, 1.589110505771637, 1.588821802520752, 1.6026055550575256, 1.6419427117347718, 1.674601403427124, 1.6651166584968566, 1.762765625, 1.7077101719856262], 'val_acc': [0.5682, 0.5991, 0.6025, 0.6027, 0.6159, 0.6249, 0.6202, 0.6385, 0.6425, 0.6267, 0.6441, 0.6457, 0.653, 0.6528, 0.6581, 0.6527, 0.6556, 0.6678, 0.6659, 0.6606, 0.6705, 0.6679, 0.6717, 0.666, 0.6681, 0.6721, 0.6791, 0.6764, 0.68, 0.6717, 0.678, 0.6764, 0.6743, 0.6872, 0.681, 0.68, 0.6866, 0.6904, 0.6875, 0.6832, 0.6802, 0.6879, 0.6888, 0.6864, 0.6859, 0.6851, 0.6852, 0.696, 0.6894, 0.689, 0.6893, 0.6812, 0.6855, 0.6839, 0.6903, 0.6888, 0.688, 0.686, 0.6864, 0.6793, 0.6874, 0.6862, 0.6834, 0.6838, 0.6789, 0.6777, 0.6787, 0.6888, 0.682, 0.6841, 0.6849, 0.6742, 0.6826, 0.6759, 0.6793, 0.683, 0.6786, 0.6805, 0.6781, 0.6766, 0.6745, 0.6735, 0.6729, 0.6786, 0.674, 0.6718, 0.6765, 0.6732, 0.6768, 0.676, 0.6731, 0.677, 0.6761, 0.6758, 0.6745, 0.6754, 0.6701, 0.6723, 0.6637, 0.6749], 'loss': [1.1732645796298982, 1.1352524357795715, 1.104189737701416, 1.077775828576088, 1.051176964712143, 1.0298537462711335, 1.009131023311615, 0.9881298980236054, 0.9695334973335266, 0.9503012888431549, 0.9336442036390304, 0.9177538747787476, 0.9015078885555268, 0.8825713824748993, 0.8695077263355255, 0.8537040432929993, 0.839390909910202, 0.8252707363605499, 0.8112089746236801, 0.7997482423067093, 0.7867113394498825, 0.7738362635850906, 0.7611192769050598, 0.7490418445825576, 0.7366310770511627, 0.7233049489021302, 0.7116056343078613, 0.699313143646717, 0.6867188101768493, 0.6763837361097336, 0.6669088642597198, 0.6545091748476028, 0.6437163274049759, 0.635359902536869, 0.6223206358909606, 0.6140420274615288, 0.6008823795437813, 0.592268802511692, 0.5831975491523743, 0.5730428659200668, 0.5620011733651161, 0.552037963795662, 0.5441964433312416, 0.5318652430295944, 0.5253029290914536, 0.5136519926905632, 0.5050107707381248, 0.492608074426651, 0.4848198200583458, 0.47692491483688354, 0.4653058981180191, 0.4600407009840012, 0.44770914335250855, 0.44233814091682433, 0.42832567846775055, 0.42456525946855544, 0.4123350598156452, 0.40399049525260927, 0.3968893409430981, 0.3860207430124283, 0.37942531708478927, 0.37099036014676096, 0.3612547080218792, 0.3529476474404335, 0.34412439815998075, 0.3351941962957382, 0.3301786405920982, 0.3209822077095509, 0.31406300128102305, 0.3047378838121891, 0.29553454686403274, 0.28708567511439326, 0.2821522420048714, 0.2728155497908592, 0.26555346252024176, 0.26076449269354346, 0.25281576637774705, 0.24280411864221096, 0.2363926580607891, 0.2298517553895712, 0.21920348714590074, 0.21550944307744502, 0.20697443268299104, 0.20019416680186988, 0.1954388048514724, 0.1871427023857832, 0.18025663066506387, 0.1761854066029191, 0.16900171189904212, 0.16202098668962717, 0.1574562421426177, 0.15094833619743586, 0.14587431555837393, 0.14197328082770108, 0.13381717543005944, 0.1319231194064021, 0.12130022035092115, 0.11913802021592855, 0.11338542714565993, 0.1079744525887072], 'acc': [0.581075, 0.59665, 0.6085, 0.62025, 0.631075, 0.6386, 0.645925, 0.654525, 0.661225, 0.6664, 0.67435, 0.6808, 0.6855, 0.69275, 0.696825, 0.7048, 0.7081, 0.714725, 0.718625, 0.72325, 0.72835, 0.733225, 0.73735, 0.741675, 0.7459, 0.7515, 0.755, 0.75895, 0.765, 0.7679, 0.77085, 0.77645, 0.7818, 0.783325, 0.787, 0.789525, 0.79335, 0.796875, 0.800075, 0.804375, 0.8083, 0.81125, 0.814525, 0.817425, 0.820175, 0.827475, 0.830325, 0.833725, 0.834375, 0.837975, 0.842, 0.846675, 0.8478, 0.850875, 0.8562, 0.857225, 0.86095, 0.866675, 0.86735, 0.872625, 0.872875, 0.8766, 0.879925, 0.884375, 0.88615, 0.88875, 0.89165, 0.8952, 0.89785, 0.899975, 0.904725, 0.905975, 0.909025, 0.9129, 0.91405, 0.917625, 0.918375, 0.923025, 0.9234, 0.92915, 0.932625, 0.932325, 0.9365, 0.938625, 0.940025, 0.943325, 0.94595, 0.946575, 0.95065, 0.952275, 0.954, 0.956125, 0.958275, 0.9592, 0.96335, 0.963025, 0.9667, 0.96775, 0.969225, 0.971925]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl4k3W6//F30jTd0i1t0kJboJRC\naUvZKqsKYgsKKCou6ICO4C6OOuoPD3M8jKOCniOjjuMo7g6CdFBcQFlkUzbZl5ayltKV7muaNs3y\n/P5g7EwHKAWSpsv9ui6uiyxPcudukk+e7ftVKYqiIIQQQogOT+3uAoQQQgjhHBLqQgghRCchoS6E\nEEJ0EhLqQgghRCchoS6EEEJ0EhLqQgghRCehcXcBV6q0tPaKlg8O9qWy0uykarou6aNzSB+dQ/ro\nHNJH53B2Hw0G/wve1uXX1DUaD3eX0ClIH51D+ugc0kfnkD46R1v2scuHuhBCCNFZSKgLIYQQnYSE\nuhBCCNFJSKgLIYQQnYSEuhBCCNFJSKgLIYQQnYSEuhBCCNFJdPjBZ9qjt99+g2PHjlBRUU5DQwPd\nu0cQEBDI/Pn/d9Flf/hhJX5+OsaMua5Vz2WxWJgyZQIzZz7EnXfec6WlCyGE6MAk1F3giSeeBs4G\n9KlTWcye/VSrl5048aZLeq4dO7ai14ewfv06CXUhhOjiJNTb0L59e1i27HPMZjOzZz/N/v172bx5\nAw6Hg5EjRzNz5kN89NEigoKCiI6OYcWKf6BSqcnJyWbs2OuZOfOhcx7zxx/XMGvWw7zzzlsUFhbQ\nvXsENpuNl1+eR3HxGbRaL/77v18kOFh/znW7d+9s+tFhNpu59967+PLLlUybdisjRowmODiYUaOu\n4c9/fg2NRoNareall14lICCQJUs+Y/PmDahUah55ZDaHDu0hNDScyZNvAWD69Dt4550PCAwMaus2\nCyFEl9XpQ/0fG0+y+2jJBW/38FBhtyuX9JhXxRm5c1yfy6onK+skX3yxAq1Wy/79e/nb3z5ErVZz\n551TuOuu5mvamZmHWbr0KxwOB3fccdM5oV5XZ+Lgwf38z/+8xJEjmWzYsI4ZM+5n9epVhISE8Mc/\nvsL69WvZuvVnNBrNOdd5eXmdt0abzcaIEaMYMWIUu3f/wtNPP0ffvnF8+OF7rFu3muHDR7F58wYW\nLfqUwsICPv/8Ux5++AH+9KeXmTz5FrKzT9G9e4QEuhCiS7PZHRw8WUasxU6AV9sMFdvpQ7296dMn\nFq1WC4C3tzezZz+Eh4cHVVVV1NTUNLtvv35xeHt7X/CxNm/eyLBhI/Hy8iY19Qbmz/8jM2bcz7Fj\nR0lOvgqAlJQJALz++qvnXPfDDysv+Njx8QkABAeH8O67b2OxNFBWVkpq6g0cP36M+PhE1Go1kZFR\nPP/8CxgM/phMtVRWVrJ160+kpt5wmR0SQoiOzVRv5acDBWzYm0+VqZHk/mE8NiWhTZ6704f6neP6\ntLhWbTD4X/FMb5fC09MTgKKiM6SlLeHjj5fg6+vLjBl3nnNfD4+Wf9n9+OMaCgoK+O1vz67h5+Xl\nkp19Cg8PNQ5H860P57tOpVI1/d9mszW7TaM5W+dbb73Ob35zHyNGjGLp0sXU15vP+1gAqak38NNP\nG9mzZzevvfbnFmsXQojOpKKmgeN5VWSermTXkWIabQ68tB6kJkfxm4n9cTTaLv4gTtDpQ729qqqq\nIjg4GF9fX44dO0pRURFWq7XVy5eXl3H6dDZffrkSjebsn/GTTz5g/fq1xMXFs2/fbsaNS2Hbti1k\nZZ0473U9e0ZTXl4GwKFDB877PNXVVURERNLY2Mgvv2wjIWEA/fr159NPP8Jms1FTU83//d8CPvxw\nESkpE3j++WeIiopqcQuDEEJ0VIqiUFlrIb+0joIyE/klJk7kV1NW3dB0n5AAb1KSI7kmqTu+3hpC\nAn3abOVRQt1NYmP74uPjy6OPzmTAgEFMmXIbCxe+RlLSwFYtv2HDj6SkTGgKdIAbb5zM008/zt//\nnsaePbv+uWlfw3//9x8JCgo+5zpfX1/+/vePmT37IUaNuhqV6txhC6ZOvYv/+q9niYiIYOrUu3jj\njf9l3LhUJkyYyOzZD6EoCg8//DgAen0IPj6+pKTIpnchROficCj8dKCAb7dmU2NuvgLm561hUJ9Q\n+kYF0a9HED3CdHio3TMMjEpRlEs7SqydudJfP229+b2zMhj8OXEij2eeeYIPPvgMtZve0B2dvB+d\nQ/roHNLHs7IKq/l87XFyimvx8fIgITqEyFA/Igx+dA/1I0zvi/rfdmf+J2f30WDwv+BtsqYunGL9\n+vX8+c9v8sQTT0ugCyE6pGO5lWzaX4BarcJHq8Fb60GVycIvh4tRgJEJ4dx5XQyBuvOfOdQeSKgL\np0hJSWHgwOHuLkMIIS5Zo9XOVz+d4sc9eee9PSLUj+nj+9KvR3AbV3bpJNSFEEJ0WacKa/hwVSZF\nFWbC9L7cf2McIQHeNDTaqG+043Ao9O4egMajY2yBlFAXQgjRJdTUNXI8r4ozFWaKys0UVZjJKarF\noSikJkdx25jeeHm2zSAxriKhLoQQotOqt9jYf6KUXw4Xk3m6Ese/HRvuoVYRZdRx17g+xPVs/5vW\nW0NCXQghRKditTnIOFXOL5nFHDxZRqPNAUB0twCG9A0l0qAjPMSX0EBvt5165ioS6i5wJVOv/urM\nmUKqq6uIi4s/5zaLpYHJk8fzyCOPM3XqXc4sXQghOqRGq51jeVXsOVrC3mOlmC1nR3AL0/syMj6M\n4fFhhOl93Vyl67k01OfPn8/BgwdRqVTMnTuXpKSkptvWr1/Pu+++i1arZdKkSUyfPp2dO3fy5JNP\nEhsbC0Dfvn154YUXXFmiS1zJ1Ku/2rNnF3a77byhvnXrzxgMBtavXyehLoTokhRFobiynvRT5aSf\nKudYbhXWf66RB/t7ce3A7gyPD6NHmK7ZkNidnctCfdeuXeTk5JCWlkZWVhZz584lLS0NAIfDwUsv\nvcTXX39NUFAQDz74ICkpKQAMGzaMv/zlL64qy+3+9re/cPhwOg6Hndtvv5vrr09lx45tfPzxIrRa\nL0JDQ3n88af49NMP8fTUYjSGM2rU1c0e48cf1/Dgg4/y1lsLKSoqIjw8HKvVyssv/w8lJcVotV68\n8MJLBAYGnnPdjh1byc/P49FHn6C2tpYHHphBWto3TJt2K8OGjcBgCGP48BG88cb//XO6VQ9efvk1\n/P39Wbz4E37+eRNqtQePPvoEW7b8RJ8+sdx442QA7rlnKu+99wkBAQHuaK0QopOrNTdyOLuCzNOV\nZOZUUFFjabotwuDHgN4hDIwJITYqqMXBYDozl4X6jh07moI6JiaG6upqTCYTOp2OyspKAgIC0Ov1\nAIwYMYLt27cTERHh9DpWnFzF/pL0C97uoVZhP8/kJC0ZbBzAbX0mX3It+/btobKygnfe+QCLpYFZ\ns+7lmmvG8NVXaTz55LMkJiaxadN6PD09mTBhIkaj8ZxAr6mpISPjEC++uIBDhw6yceM67rnnXr7/\n/lvCwsJ58cUFrFu3mm3bfkZRHOdcd6GBYRobG7nmmjFcddUIdu7cwe9/P4fY2L4sWvQO69evZciQ\nZLZu/ZlFiz4lPz+XZcuWcOutt7No0TvceONkjh49Ss+evSTQhRBO51AUNu7N58ufsmi0nl0b1/l4\nclWckYRoPYnRevQBMt8EuDDUy8rKSEj411Rzer2e0tJSdDoder2euro6Tp8+TUREBDt37mTYsGFE\nRERw8uRJHnnkEaqrq5k9ezajR49u8XmCg33RaC58CoJvgRYPdcu/2C52+zmP6aNtcZi+X/n7e+Pr\n+6/7njp1lMzMdH7/+8cAUKkUoIGbb57MwoULuPnmm5k0aRIRERH4+mrR6bzPeZ5Nm1Zz3XXXERkZ\nyp133sa8efN48snHyc09xZgxYzAY/PnNb87O+PbCCy+cc93y5cubavLyUvDwUGMw+KNSwbXXjkSn\n0xETE8Xrr7+OxWKhuLiYW2+9lTNnTpOcPISwsEDCwgYwdOirALz+ejUajY0NGzYwdeqtreqLaJn0\n0Dmkj87h7j4WldfxVtp+MrLK8ff1ZFpqPwb3M9K7eyDqS/zudqe26mObHSj370PMq1QqXn31VebO\nnYu/vz+RkZEA9OrVi9mzZ3PjjTeSl5fHvffey7p165rmHz+fykpzi897Q8R4bogYf8HbL3dM3tYs\nU1vbgNnc2HTfxkYHkyZN4Z577m12v2uvHU9i4lB+/nkzs2Y9wPz5r2M2N2IyNZzzPCtWfENxcRGT\nJt0EQG7uafbuzaCx0U5VlbnZ/c93ncn0r5oqK6uw2x2UltbicChUVTVQX6/wP//zR+6//0Guumo4\nixd/Sl2dhbq6RurqLOfUM2ZMCt98s4pdu3YxZcpdMk70FZKxtp1D+ugcbd1HRVGoa7BRVWuhymQh\np7iWVdtzsFjtDI4N5d4J/ZqGaC0vN7VZXVeqU4z9bjQaKSsra7pcUlKCwWBoujxs2DCWLl0KwMKF\nC4mIiCAsLIyJEycC0KNHD0JDQykuLiYqKspVZbap+PhEPvjgXaZNm05jYyPvvfdXnnrqWT755APu\nuONubrllKuXlZeTkZKNWq7Hb7c2WLy0toaAgn+XLv2uaa/3DD99rNt3qmDHXsWXLZnJzc857Xbdu\nEa2ebtVisbBz53YGDRpCXFw8S5Z8ht1up7Kykjff/F9efvl/GT/+BubOfY64uL54ebXf8ZCFEO1X\ncYWZDXvz2ZZRRL2l+bzjft4a7rshnuHxYV3qgLfL5bJQHz16NG+//TbTpk3j8OHDGI1GdDpd0+0P\nPPAAr732Gj4+PmzatIn777+f7777jtLSUmbNmkVpaSnl5eWEhYW5qsQ2N2jQEBITk3j44fsBpenI\ndYPByO9+9wj+/gEEBgYyffp9aDSeLFjwJwIDg0hJmQDA+vXrSE29oSnQ4ex0q3PmPM3HHy9h3749\nTVOrvvDCnwgICDjnOm9vbz7//FOeeOJhRo4cfd4PydSpdzFnztN07x7B7bffxVtvLWTcuBTGjUvl\n8ccfBOCRR2YDEBpqQKvVMnnypR9jIITouhRF4fDpCtbvySc9qxwFCNRpiesRSpDOiyCdliB/L5Ji\nQgn0u/DWWtGcS6deff3119mzZw8qlYp58+aRmZmJv78/qamprFu3jnfeeQeVSsXMmTO5+eabMZlM\nPPvss9TU1GC1Wpk9ezZjxoxp8Tlk6lX3qqys4LnnnuLrr7+ivLzO3eV0ePJ+dA7po3O4qo8n8qtY\nvjmLk/nVAMREBJAyNIqh/QwdZoz1S9GWm99lPnX58F+2zZs38MknH/Lkk88wYcJ10kcnkPejc0gf\nncPZfSwsq+Orn7LYf+LsLsDBsaFMHtWL6G6d+6yZTrFPXXR+Y8dez9ix17u7DCFEO1VZa+FEfhUn\n8qs5mV9NbkktigJ9IgK547oYYiOD3F1ipyOhLoQQwmkqahrYeaSYnZnF5Bb/6wh1jYeKPhGBTBjW\ng8GxoXLQm4tIqAshhLhih7LK+WHHaY7/cz+5h1pFYm89/XsE0ycykF7h/ni2MKaIcA4JdSGEEJet\n3mJj2YYTbDl0BhXQLyqI4QlhJPczovPxdHd5XY6EuhBCiFZRFKXZZvNjuZV89P0RyqobiDLqeGBy\nPFFGXQuPIFxNQl0IIUSLjpyuIG3TSfJKTHhrPfDWatB6elBSYQYVTBrZkylXR3fK09E6Ggl1IYQQ\n51VYauK9rw6x/0QZKqBXN3+sNgWL1Ya5wUqUUceMCf2IiQh0d6ninyTUhRBCNONQFL7dks3qnTnY\n7Ap9IwOZlhJLr/DOfT55ZyChLoQQoond4eDTH46yLaMIY7APt4+JYWg/g5yC1kFIqAshhADAanPw\n/srD7D1WSnS3AF55bDQNdRZ3lyUugYS6EEIILFY776xIJyO7grgeQTwxNQl/X62EegcjoS6EEF2M\n1eZg4758iivMmC02zBYbJRX1lFTVkxQTwmO3JKL1lIFiOiIJdSGE6ELKqup599sMss80n2DEQ63i\n6gHduPeGfnJqWgcmoS6EEF3EgZNlfLQqk7oGG6MHhHPD8J74eWvw8dKg1ajlYLhOQEJdCCE6KYvV\nTnl1A+U1DRzOrmDd7jw8NWruvzGOawZ2d3d5wgUk1IUQohOx2R1s2lfAml25VNY2P8jNGOTDY7cm\n0iPswvNxi45NQl0IITqJI6crWLr+BAVldfh4eRDfK5jQQG9CArwJDfJhUJ9QfLzka78zk7+uEEJ0\nUA5FoaSyntziWnYfLWHvsVJUwJhB3bn12t4E+GrdXaJoYxLqQgjRgSiKwq4jJWzYm09eiQmL1d50\nW5+IQH6T2pee4bJ5vauSUBdCiA6irKqexeuOk36qHLVKRfdQX6KM/vQI09Er3J++UUFyBHsXJ6Eu\nhBDtnMOhsH5PHiu2nKLR6iC+VzD33hCHMcjH3aWJdkZCXQgh2imHQ2HX0WJWbjvNmXIzOh9PZozv\nx6jEcFkjF+cloS6EEO2Mw6Gw+2gJ323L5ky5GbVKxTVJ3Zg6NkYOfhMtklAXQgg3M9VbyTxdwekz\ntZwuquF0US0NjXbUKhVXJ3Vj8qhesqldtIpLQ33+/PkcPHgQlUrF3LlzSUpKarpt/fr1vPvuu2i1\nWiZNmsT06dMvuowQQnQ2macreO/bw5jqrQCogPAQX/r1COaGYVEYg33dW6DoUFwW6rt27SInJ4e0\ntDSysrKYO3cuaWlpADgcDl566SW+/vprgoKCePDBB0lJSSE3N/eCywghRGeiKAqrd+by1U9ZqFUq\nJo/qRXzPYHqG+8sAMeKyueyds2PHDlJSUgCIiYmhuroak8mETqejsrKSgIAA9Ho9ACNGjGD79u3k\n5eVdcBkhhOgszA02Pv7hCPuOlxLs78VjtyQSExHo7rJEJ+CyUC8rKyMhIaHpsl6vp7S0FJ1Oh16v\np66ujtOnTxMREcHOnTsZNmxYi8sIIURHpigKWYU17MwsZveRYmrMVuJ6BPHIlEQC/OTgN+EcbbaN\nR1GUpv+rVCpeffVV5s6di7+/P5GRkRdd5kKCg33RaDyuqDaDQUZfcgbpo3NIH52jvfSxvLqe1dtP\ns2lfPiUVZgAC/LTcPb4fd6X0xaOdz13eXvrY0bVVH10W6kajkbKysqbLJSUlGAyGpsvDhg1j6dKl\nACxcuJCIiAgsFkuLy5xPZaX5iuo0GPwpLa29oscQ0kdnkT46R3voY1ZBNT/uyWPvsVLsDgUvrQcj\nE8IZkRBG/57BaDzUVFTUubXGi2kPfewMnN3Hln4guOwn4ujRo1m7di0Ahw8fxmg0NtuM/sADD1Be\nXo7ZbGbTpk2MHDnyossIIUR7d7KgmvmL9/LK4r3sOlJCeIgvv70xjjefuJoHb4pnQO8QNO187Vx0\nXC5bUx8yZAgJCQlMmzYNlUrFvHnzWLFiBf7+/qSmpnLnnXcyc+ZMVCoVDz30EHq9Hr1ef84yQgjR\nEVTWWvhycxY7DhcBMKhPKKnJkcT1DJbR30SbUSmt2XHdjl3pJg3ZvOQc0kfnkD46R1v20dJoZ/3e\nPFZtz8FitdMzzJ97UmOJjQxqk+d3JXk/Okdbbn6XkyGFEOIy1DVY2bA3n/V78jHVW/H39eTulFiu\nHtANtVrWzIV7SKgLIcQlqKhpYMPefDbuL8DSaMfPW8OUq6NJTY7E19vT3eWJLk5CXQghLkJRFE7k\nV7N+Tx77jpfhUBQCdVqmjI5mzKDuMgKcaDfknSiEEOehKAp5JSYOZZWz+2gJeSUmAHoYdVw/NJIR\nCWF4XuEYGUI4m4S6EEL8m6IKM2t25pJ+qpzKWgsAapWK5DgjKUMjiY0MlKPZRbsloS6EEJxdM9+W\nXsSSH49jsdrR+XgyIiGMpJgQEqND0PnI/nLR/kmoCyG6vHqLjcVrj/FLZjE+Xh48dFM8w/qHyVHs\nosORUBdCdGnHciv55IejlFTV07t7AA/fnIAhyMfdZQlxWSTUhRBdUmFZHV9uzuLAyTJUwMQRPbnl\nmmgZwlV0aBLqQogupdpk4Zut2fx8sBBFgb6Rgdwxrg8x3WU+c9HxSagLIboEh0Nh4758vt5yinqL\nnW4hvtw+NoZBfULlaHbRaUioCyE6vewzNfx9zTFyimvx9dIwfXxfxgzqjodaNrWLzkVCXQjRaSiK\nwuYDheSV1lFjstBotdPQaCeroBoFGJUYzh3X9SHQT+vuUoVwCQl1IUSnYLM7+Gz1UbZlFDW7XgVE\nGnXckxJLvx7B7ilOiDYioS6E6PDMDVb+uiKdo7lVRHfz57kZV2GzWNFq1Hhq1LLPXHQZEupCiA6t\ntKqeN5cf5Ey5mSF9DTx4UzyRYTIPuOiaJNSFEB2G1ebg+x2nyS02UVHTQEWtBVO9FYDxV0Vx53V9\nZBQ40aVJqAshOgRLo52/fp3O4ewKALSeavT+3kQZdYyID+Oagd3dXKEQ7iehLoRo98wNVt788hAn\n86tJiglh1qT+6Hw8ZV+5EP9BQl0I0a7V1DXy57QD5JaYGNbfyAOT42UoVyEuQEJdCNFuZZ+p4YOV\nmRRVmBkzqDszxveTfeZCtEBCXQjR7pgbrHz18yk27ytAAW4c3oPbx8bI5nYhLkJCXQjRbtSYG0nP\nKmf5ppPUmK10C/Fl+vh+9O8pg8YI0RoS6kIIt6mstbBmZy55JbUUlNVRaz57eppWo2bqmN5MGNZD\n9p8LcQkk1IUQbpFbXMtbXx6istaCCggN8iameyARBj/GDOxOaJCPu0sUosNxaajPnz+fgwcPolKp\nmDt3LklJSU23LVmyhO+++w61Wk1iYiJ/+MMfWLFiBW+99RY9evQAYNSoUTz66KOuLFEI4QaHsyt4\n5+t0Ghrt3D42huuHROKl9XB3WUJ0eC4L9V27dpGTk0NaWhpZWVnMnTuXtLQ0AEwmEx999BHr1q1D\no9Ewc+ZMDhw4AMDEiROZM2eOq8oSQrjZlkOF/H3NMVQqeGRKAsP6h7m7JCE6DZeF+o4dO0hJSQEg\nJiaG6upqTCYTOp0OT09PPD09MZvN+Pr6Ul9fT2BgoKtKEUK0A0UVZr7bms0vmcX4eWt4YmoSfaOC\n3F2WEJ2Ky0K9rKyMhISEpst6vZ7S0lJ0Oh1eXl48/vjjpKSk4OXlxaRJk4iOjmb//v3s2rWLWbNm\nYbPZmDNnDvHx8S0+T3CwLxrNlW22Mxj8r2h5cZb00Tk6Wx8Ly0yk/XiczXvzcCgQ3T2A/zcjmUij\na19nZ+uju0gfnaOt+thmB8opitL0f5PJxKJFi1izZg06nY777ruPo0ePMnDgQPR6PWPHjmX//v3M\nmTOHlStXtvi4lZXmK6rLYJDZnJxB+ugcHb2PNruD00W15JWYzv4rriX7TC0ORSHC4MeU0dEM6WdA\nrcKlr7Oj97G9kD46h7P72NIPBJeFutFopKysrOlySUkJBoMBgKysLKKiotDr9QAkJyeTkZHB7bff\nTkxMDACDBw+moqICu92Oh4ccQCNEe1dUYeZvX6eTX1rXdJ2HWkXPcB03DO/J0H4G1DJ4jBAu5bJQ\nHz16NG+//TbTpk3j8OHDGI1GdDodABEREWRlZdHQ0IC3tzcZGRmMGTOGDz74gG7dujF58mSOHz+O\nXq+XQBeiA9hztISPfzhCQ6Od4fFhJPTSE2XU0T3UD0+NnGcuRFtxWagPGTKEhIQEpk2bhkqlYt68\neaxYsQJ/f39SU1OZNWsW9957Lx4eHgwePJjk5GQiIyN57rnnWLZsGTabjVdeecVV5QkhnMBmd/Dl\n5izW7c5D66nmoZviGZEQ7u6yhOiyVMq/7+zugK50P4XsM3IO6aNzdKQ+FpTV8fH3R8g+U0O3EF8e\nu3UAEaF+7i4L6Fh9bM+kj87RKfapCyE6J7vDwZqduXy7NRubXWFEQhgzxvfDx0u+ToRwN/kUCiFa\nLb/ExMc/HOF0US2BflrundCPwX0N7i5LCPFPEupCiIsyN9j4dms2G/bm41AURiWGM+36WHQ+nu4u\nTQjxbyTUhRAX5FAUtqcX8eXms1OhGoN8uCc1lqSYUHeXJoQ4Dwl1IQRwdl/53mOlFJTWUVlrodJk\noaTSTGlVA1pPNbdd25sJw6LwvMIRHIUQriOhLkQXpygK6acqWL7pJAVldc1u8/XSMCI+jNvHxqAP\n8HZThUKI1pJQF6ILyysx8Y+NJzh8uhKVCq4d2I3h8eHo/b0I8vfCy1PWyoXoSCTUheiCThXW8MMv\nOew/XooCJETrueu6PkQade4uTQhxBSTUhehCDmdX8P2O0xzNrQIgups/U67uTVJMiHsLE0I4hYS6\nEF3Ej3vy+GL9CeDsmvnEET2J6xGESiZZEaLTkFAXogtIP1XOsg0nCPTT8rvbk4juFuDukoQQLiDT\nJwnRyRWW1fHetxl4qNXMnjpAAl2ITkxCXYhOzFRv5S9fHqLeYmfmxDhiuge6uyQhhAtJqAvRSTVa\n7fzt63RKquqZPKqXTIkqRBcg+9SF6GRqzI1s2lfAxn351JqtDO1n4JZrot1dlhCiDUioC9FJFFeY\nWbsrl20ZRVhtDvy8NUwa2ZPJo3qhliPchegSJNSF6ODySkx8v+M0u4+WoCgQGujN+KuiuDqpG95a\n+YgL0ZXIJ16IDir7TA3fbc3mYFY5AFFGHZNG9iS5nxG1WtbMheiKJNSF6GCKK8ys+PkUu4+WANAn\nMpDJI3sxoLdeBpIRoouTUBeig6gyWVi57TQ/HyzE7lCI7hbA7WNj6N8z2N2lCSHaCQl1Idq58uoG\nVu/M4eeDZ7DZHYTpfZl6bW+G9jPImrkQohkJdSHaqdKqelZtP832jCLsDoXQQG8mjezJ6AHd0HjI\nEBNCiHNJqAvRztgdDtbtzuObLdlYbQ7C9b5MGtmT4fFhEuZCiBZJqAvRjpwqqObPS/aSU1yLv68n\nv70hjuHxYXI0uxCiVSTUhWgHbHYH323L5odfcnE4FEYlhjPt+lh0Pp7uLk0I0YG4NNTnz5/PwYMH\nUalUzJ07l6SkpKbblixZwnfffYdarSYxMZE//OEPWK1Wnn/+eQoLC/Hw8GDBggVERUW5skQh3O5M\neR3vr8wkp6gWY7AP01P7ktg7dH7rAAAgAElEQVQ7xN1lCSE6IJeF+q5du8jJySEtLY2srCzmzp1L\nWloaACaTiY8++oh169ah0WiYOXMmBw4cIDs7m4CAABYuXMjWrVtZuHAhb775pqtKFMKtFEVh84FC\n0jacoNHm4OoB3Xhi2mDqahvcXZoQooNy2VE3O3bsICUlBYCYmBiqq6sxmUwAeHp64unpidlsxmaz\nUV9fT2BgIDt27CA1NRWAUaNGsW/fPleVJ4Rb5ZeaeGP5QRavPYanRs1jtyQyc1J/fL1lc7sQ4vK1\nak1dUZRLPh+2rKyMhISEpst6vZ7S0lJ0Oh1eXl48/vjjpKSk4OXlxaRJk4iOjqasrAy9Xg+AWq1G\npVLR2NiIVqu94PMEB/ui0XhcUm3/yWDwv6LlxVnSx4srKq9jydqj/LQvH0WBQbEGnpw2mNAgn6b7\nSB+dQ/roHNJH52irPrYq1K+77jqmTJnC7bffftn7uBVFafq/yWRi0aJFrFmzBp1Ox3333cfRo0db\nXOZCKivNl1XPrwwGf0pLa6/oMYT08WJqzY18uzWbnw6cHQ0uyqjjtmt7kxQTgmK1NfVO+ugc0kfn\nkD46h7P72NIPhFaF+vLly1m7di1z585Fo9Fw2223MWHChBbXoI1GI2VlZU2XS0pKMBgMAGRlZREV\nFdW0Vp6cnExGRgZGo5HS0lLi4uKwWq0oitLicwjR3tnsDjbtK+DbrdmYLTaMwT7cek1vrupvlOlQ\nhRBO16p96gaDgenTp7N48WL++Mc/8sUXX3DNNdfwxhtvYLFYzrvM6NGjWbt2LQCHDx/GaDSi0+kA\niIiIICsri4aGswcEZWRk0KtXL0aPHs2aNWsA2LRpE8OHD7/iFyiEu2RklzPv4118seEEAHenxPLy\nA8PPnncugS6EcIFWH/2+e/duVqxYwd69exk/fjwvvfQSmzdv5sknn+S999475/5DhgwhISGBadOm\noVKpmDdvHitWrMDf35/U1FRmzZrFvffei4eHB4MHDyY5ORm73c727du5++670Wq1vPrqq059sUK0\nhSqThS/Wn2D30RJUKhg7OIJbrokmwFe2OgkhXEultGLHdWpqKhEREdx5552kpqbi6fmvI3Tvvvtu\nvvjiC5cW2ZIr3U8h+4ycQ/oIDkXhpwOFfLk5i3qLjZiIAGaM70ePsNYfICN9dA7po3NIH52j3e1T\n//DDD1EUhV69egGQmZlJfHw8AEuXLr3yCoXowBwOhfRT5azacZqsghp8vDyYMb4vYwZHyGZ2IUSb\nalWor1ixgpKSEhYsWADA+++/T2RkJM8++6xM/Si6rBpzI1sPnWHz/gLKqs8eH5Lcz8DdKX0J9vdy\nc3VCiK6oVaG+c+dOli1b1nT5zTff5O6773ZZUUK0Z5ZGO6t2nGbtrjxsdgdaTzXXDuzOdYMj6Bku\n5/QKIdynVaFutVqbDQJTV1eHzWZzaWFCtDeKorDveClfbDhBRY0FfYAXE67qwegB4TISnBCiXWhV\nqE+bNo2JEyeSmJiIw+EgPT2d2bNnu7o2IdoFc4OV43nVbNyfT8apCjzUKiaN7Mnkkb3w0l7ZaIZC\nCOFMrQr1O+64g9GjR5Oeno5KpeK//uu/ms45F6IzKqmqZ+PefI7lVpFbXMuvp4jE9wrmN6l96Rbi\n59b6hBDifFp9nrrZbG4aAe7UqVO8/PLLrF692mWFCeEuJ/Or+ctXhzDVW9F4qIiNCiKuRxD9ewbT\nNypIDg4VQrRbrQr1l19+mW3btlFWVkaPHj3Iy8tj5syZrq5NiDa391gJ76/MxG5X+E1qX65O6oaX\np2xiF0J0DK0aJjY9PZ3Vq1cTFxfHV199xccff0x9fb2raxOiTf24O4+/fZ2BWqXid7cncf3QSAl0\nIUSH0qpQ//Wo918nWUlMTJS5zkWn4VAU/rHxJF9sOEGAn5bnfzOEpJgQd5clhBCXrFWb36Ojo1my\nZAnJycncf//9REdHU1srQweKjs/ucPDpD0fZllFEtxBfnr5zIKGBPhdfUAgh2qFWhfqLL75IdXU1\nAQEBfP/995SXl/Pwww+7ujYhXKrRaue9bw9z4GQZ0d0CePrOgeh85HxzIUTH1apQnz9/Pn/4wx8A\nuOmmm1xakBBtwdxg4y9fHuR4fjUJvYJ5/LYBeGtbfTKIEEK0S636FvPw8GDHjh0MGTKk2QxtanWr\ndskL0W40Wu38fLCQ1Ttzqay1kBxn5MHJ8Xhq5L0shOj4WhXqy5cv57PPPuPfZ2lVqVQcOXLEZYUJ\n4UwNjTY27S9g7a48auoa0XqqmTyqJ7dc3Ru1Ws47F0J0Dq0K9b1797q6DiFcwlRvZcPefNbvyaOu\nwYa31oNJI3uSelUUAb5ad5cnhBBO1apQf+utt857/ZNPPunUYoRwliqThXW78th0oABLox0/bw23\nXB3N9cmR+MnkK0KITqrV+9R/ZbVa2b17N/Hx8S4rSogrcbqohoXLDlDXYCNIp+XWq6O5dlB3ORBO\nCNHptepb7j9nZLPb7TzxxBMuKUiIK5F95myg1zfamDauD9cNiZSD4IQQXcZlrbrYbDZyc3OdXYsQ\nV+RUYQ0L0w7Q0GjjgcnxjEwId3dJQgjRploV6mPGjGk2M1V1dTW33nqry4oS4lJlFVbz57QDNDTa\nefCmeEbES6ALIbqeVoX60qVLm/6vUqnQ6XQEBAS4rCghWsuhKGzeX8DyTVlYbQ4evjmBYf3D3F2W\nEEK4Rat2NtbX17Ns2TIiIiLo3r07CxYs4MSJE66uTYgWnSmv47Ul+/h83XE0HioevSVRAl0I0aW1\nKtRffPFFxowZ03R56tSp/OlPf3JZUUK0xGZ38P2O08z7eDcn8qsZ2s/Ayw8MZ2g/g7tLE0IIt2rV\n5ne73U5ycnLT5eTk5Gajy13I/PnzOXjwICqVirlz55KUlARAcXExzz77bNP98vLyeOaZZ7Barbz1\n1lv06NEDgFGjRvHoo49e0gsSnZeiKBw8Wc6yjScoqawnwE/L9NS+JMcZ3V2aEEK0C60KdX9/f5Yu\nXcrw4cNxOBxs2bIFPz+/FpfZtWsXOTk5pKWlkZWVxdy5c0lLSwMgLCyMxYsXA2ePpJ8xYwbjxo1j\n7dq1TJw4kTlz5lzhyxKdTUGpiWUbTnD4dCVqlYrrh0Yy5epomVVNCCH+TatCfcGCBSxcuJAvvvgC\ngCFDhrBgwYIWl9mxYwcpKSkAxMTEUF1djclkQqfTNbvf119/zYQJEy76I0F0XVsOFfLZ6mM4FIXE\naD13XR9LRKi8X4QQ4j+1KtT1ej0PPvggvXr1AiAzMxO9Xt/iMmVlZSQkJDR7jNLS0nNCffny5Xz8\n8cdNl3ft2sWsWbOw2WzMmTNHRq7r4lbvzGH5piz8vDXMmhzPwJiQZqdXCiGE+JdWhfobb7xBSUlJ\n09r5+++/T2RkZLP94hdzvn3w+/fvp3fv3k1BP3DgQPR6PWPHjmX//v3MmTOHlStXtvi4wcG+aDQe\nLd7nYgwG/ytaXpzlzD4qisKnqzJZsTmL0EBv/vTwKKLCusbfSd6PziF9dA7po3O0VR9bFeo7d+5k\n2bJlTZfffPNN7r777haXMRqNlJWVNV0uKSnBYGh+dPLmzZsZOXJk0+WYmBhiYmIAGDx4MBUVFdjt\n9mZjz/+nykpza17CBRkM/pSW1l7RYwjn9tHucPDZmmNsPXSGcL0vz9w1CG81XeLvJO9H55A+Oof0\n0Tmc3ceWfiC06pQ2q9VKY2Nj0+W6ujpsNluLy4wePZq1a9cCcPjwYYxG4zmb3tPT04mLi2u6/MEH\nH7Bq1SoAjh8/jl6vbzHQRedTVGFm/uJ9bD10hl7h/jw/fQghgd7uLksIITqEVq2pT5s2jYkTJ5KY\nmIjD4SA9PZ377ruvxWWGDBlCQkIC06ZNQ6VSMW/ePFasWIG/vz+pqakAlJaWEhIS0rTMTTfdxHPP\nPceyZcuw2Wy88sorV/DSREei/HNkuLSNJ2m0ORiREMaM8f3w8ZKZ1YQQorVUSmtOOAd2795NZWUl\nKpWKuro6Fi1axOrVq11d30Vd6SYN2bzkHFfSxyqThY9/OELGqQr8vDXce0McV3XRc8/l/egc0kfn\nkD46R1tufm/VatArr7zC1q1bKSsro0ePHuTl5TFz5kynFSi6rv3HS/lk9VFM9VYSo/XcP7E/wf5e\n7i5LCCE6pFaF+qFDh1i9ejUzZsxg8eLFZGRk8OOPP7q6NtGJWRrtLNt4gp8OFOKpUfOb1L6MGxIh\np6sJIcQVaFWoa7Va4OwBc4qikJiYyGuvvebSwkTnlX2mhvdXZlJcYSbKqOOhmxNkMBkhhHCCVoV6\ndHQ0S5YsITk5mfvvv5/o6Ghqa2U/i7g0NruDldtO8/2OHByKwoRhUdx2bQyemladhCGEEOIiWhXq\nL774ItXV1QQEBPD9999TXl7Oww8/7OraRCeSV2Lio1WZ5JaYCAnwYubE/vTv1fKohEIIIS5Nq0Jd\npVIRFBQEnD3tTIjWUhSFdbvz+HJzFnaHwrUDu3HXuFg5VU0IIVxAvlmFy1isdj5dfZSdmcUE+mm5\nf2IcSTGh7i5LCCE6LQl14RKlVfX8dUU6eSUm+kQE8titiQTp5FQ1IYRwJQl14XSZpyt495sM6hps\njB0cwT0psWg85GA4IYRwNQl14VQb9+Wz9McTqNXw2xvjuHZgd3eXJIQQXYaEunAKu93B5+uOsXFf\nAf6+njxxWxJ9IgPdXZYQQnQpEuriipkbrPzlw184cLyUCIMfT05NIjTIx91lCSFElyOhLq5IfomJ\nd77JoLjCTFJMCA/fnCCnqwkhhJvIt6+4bFsOFfL5uuNYbQ5uG9uHicOiUKtl7HYhhHAXCXVxySxW\nO5+vO8a29CJ8vTQ8cnMC40f3likahRDCzSTUxSXJKqzmkx+OUlhWR89wfx67JRGD7D8XQoh2QUJd\ntEpDo40VP51iw958FOD6IZHcOa6PTMYihBDtiIS6uKj0U+X8fc1RymsshOl9uf/GOPpGBbm7LCGE\nEP9BQl20aGdmMe9/dxi1WsXkUT25aVQvPDUe7i5LCCHEeUioiwvKOFXOh6sy8fby4Jm7BtO7e4C7\nSxJCCNEC2SEqziuroJq/fp2OSqXid1OTJNCFEKIDkFAX5ygoq+PN5Qex2hw8OiWBfj2C3V2SEEKI\nVpDN76KJoijsPVbKkvXHqWuwcf/EOAb3Nbi7LCGEEK0koS4AOJ5XxfJNJ8kqrEGtUjHt+liuSZIZ\n1oQQoiORUO/izA1WPlx1hAMnywBI7mfgtjExhOt93VyZEEKIS+XSUJ8/fz4HDx5EpVIxd+5ckpKS\nACguLubZZ59tul9eXh7PPPMMN9xwA88//zyFhYV4eHiwYMECoqKiXFlil6YoSlOg940M5I5xfYjp\nLtOlCiFER+WyUN+1axc5OTmkpaWRlZXF3LlzSUtLAyAsLIzFixcDYLPZmDFjBuPGjWPVqlUEBASw\ncOFCtm7dysKFC3nzzTddVWKXt2ZXLgdOltG/ZzDP3DVIJmMRQogOzmVHv+/YsYOUlBQAYmJiqK6u\nxmQynXO/r7/+mgkTJuDn58eOHTtITU0FYNSoUezbt89V5XV5x3Ir+WrzKYJ0Wh6+OUECXQghOgGX\nramXlZWRkJDQdFmv11NaWopOp2t2v+XLl/Pxxx83LaPX6wFQq9WoVCoaGxvRarUXfJ7gYF80VzjC\nmcHgf0XLdzSVtQ18sCoTVPD8fcOI6RXilMftan10Femjc0gfnUP66Bxt1cc2O1BOUZRzrtu/fz+9\ne/c+J+hbWuY/VVaar6gug8G/S00Z6nAoLEw7QEWNhTuui8Hor3XK6+9qfXQV6aNzSB+dQ/roHM7u\nY0s/EFy2+d1oNFJWVtZ0uaSkBIOh+TnPmzdvZuTIkc2WKS0tBcBqtaIoSotr6eLSFFeaeW3pPo7k\nVDI4NpQbhvVwd0miHbE77Hxz8gfSyzLdXYoQ4jK5LNRHjx7N2rVrATh8+DBGo/GcNfL09HTi4uKa\nLbNmzRoANm3axPDhw11VXpfiUBR+3JPHvI92cSK/mqH9DMyaFI9KJfvRxb9sK9zJj7mbeT/972SU\nHXF3OUKIy+Cyze9DhgwhISGBadOmoVKpmDdvHitWrMDf37/pYLjS0lJCQv61P3fixIls376du+++\nG61Wy6uvvuqq8rqMyloLi747zPG8KnQ+nsyc1J+r4owS6KIZs7WeVdnr8PLQ4lAUPsxYzOxBD9In\nKNrdpQkhLoFKac2O63bsSvdTdOZ9Rg2NNhZ8vo+8EhND+xqYPqEfgX6u2Z3RmfvYltzVxxUnV7Eh\n92em9L6R7rpwFqV/hpeHlqeHPEqErlub13Ol5P3oHNJH52jLfeoyolwn5XAovP9dJnklJsYOjmDG\n+L6ydu5GGWVH+OH0eoK0AYzvdR29AtrP8Qyl5nI2521D7x3MdVFX4+nhyb397+LTzC/464EPuS9+\nGkFegfhofPD19EGNiga7hQabBYvdgt47GG+N12U9d2b5Mb7NWk03vzBig3rTJygao69B3qtCXCYJ\n9U7qy5+ymgaWuSclVr4k3aTKUs2Xx79jf2k6ADnAwbLD9Avuw4Se4+gbHNPqv02jvZEjFScoMZdS\nYi6jpL4Uq8PGUONAhocPRaf1u6wav8n6Abti55aYG/H08ATgqvDB1NnMLD/+LW8f+KDF5f21OuYk\n/45g76BLet4TlVm8n/4ZVoeNfFMhu4v3Nz1euK+RUJ8QQrz1hProiQ3uTZBXxxjtsN7WwGeZy4jX\n9+XayFHuLkd0MRLqndCWQ4Ws2ZlLmN6Xx25NROMhM+xeqdzafNbn/MRNvW/A4Hvx8/oVRWFLwQ6+\nzVpNg91C78Ce3N1vKiZrHWtPb+Ro5QmOVZ4kLjiW6f3vuGggNtqt/Hnfu+TVFjRdp0KFSqUipyaP\n77JWM9CQyLDwIYT6hKDT+uGr8UGtavlvf6LyFAdK04kO6MEQ48Bmt42NHE2wVyDZ1bmYbfWYbfXU\nW+tRUPD28MJL40Wj3cqB0nQ+PryEpwY/goe6dWNGZFfn8u6hT3AoCo8m3U+Ij54Tlac4WXWKU9U5\nnKg6xYmqU81ea+/Angw2JjHIkIi/Vne2Jms9DfYGIvy6Nf0g+XeKorD06JdkVecQqetGj4BIonQR\n9AiIxEfj3apaL9UP2T+SXpZJelkmnh5aRnZLdsnzCHE+sk+9k+0zyjhVzltfHsJb68F/35tMWBtN\nzNLZ+vjvFEVh4d6/kV2TQ7BXEE8NeYRQH32Ly6w6tZbVpzfgo/HhlpgbGdV9WLOAzanJY9WpdWRW\nHMNX48PdcVMZYkw6bx8VRWHxkX+ws2gvgwwDGBY+GKOvgVBvPRZ7I7uK9rKtcBdF5pJmy6lVanSe\nfui9gwn10RPirUfvHYRa5YFdseNQHGwr3EmB6QzPDn2c6MCel9WbTw4vZW/JQVJ7jOWWPhOb3Z5Z\nfowjFcfpGRBFv+A++Gt15NcW8ub+RTTYGpiVOJ3BxgHnPK7VbqWioZKyhgqK6kpIL8vkZFU2Cuf/\nugr3NfLM0Mfw9Tz7fv+1jxvztvDViZWoVWociqPp/p5qDSO7XcW4qGtb9SOttQpMZ3h191sEeQXS\nYGugwW7hkaTfkhASd8FlGu2NlNVX4OfpR6BX+xropTN/rttSW+5Tl1DvJG9ah6Lww44cvt5yCrVK\nxe/vGkT/nsFt9vydpY/nc6Iyizf3LyLIK5AqSzV672CeGvwIIT7n7++mvK18eeI7Qr31PD300Qtu\nNlYUha2FO/nqxEqsDivDw4fy6KjfUFdla3a/n/K384/j39AzIIqnhzyKp/rcDWyKonCqOofM8qPU\nNJowWeswWeuoaaylsqEKu2K/4OtLDhvE/Qn3XEJHmqu3NfC/u/9CSX0ZjyT9lgGh8TTaG1lx8nu2\nFOxodt/ufuHUNNZistZxb/+7GN5taKufp9pSy6GyDA6VZWJ32PH95z7+mkYT6WWZ9A3uw+MDZ6JR\nazAY/NmddZg/730XX40Pzw97EpvDRm5tAbk1+ewrOUh5QyUqVAwyDmBE+FDsiuPs1ghbPRqVhhHd\nktGeZ+3/QhRF4Y1975FVnc1jA2fi7eHN2wfeR4WKp4Y8Qs+AKByKg6yq0+wrOUhebSHlDRXUNJ79\n3Og8/Zg34rmmHybtQWf+XLclCfVLIKEOdQ1WPlyZycGscoL9vXjslkRiItp2/2Nn6OOF/PXAhxyp\nOM4zQx/neOVJVp5aS6i3nqeGPHLOZvNdRfv4LHMZgVp/fj/0MUJ9Lr4WWFxXwqeZy8itzSfIO4Dr\nI6/l6ogRaD20nKzK5q39i84G01VPXvJ+awCH4qDKUk15fQUVDVXA2bV4tUqNRq2hX3Cfyz7Q7Vd5\ntYW8vveveKm1TO9/B99krabYXEI3vzBu7n0DRXUlHKs8SVZ1NlaHjbv63uK0/c0OxcGHGZ9zsDSD\nEd2SmR53B75BHjy7+hUqG6qYPegB4vSxzZaxO+zsL01nfc5m8kyF533cHv6RPDTg3lb3fOeZvfz9\nSBoDQxN4KOk+AA6WZvBB+mL8PH1JDhvEgdIMqizVwNm/gd4riFCfEBQUjlWeZFzUNUyNvemcxz5R\neYqM8iNMik5F69HyGSw2h42NeVvYUvALV3cfTmrPsRfdDXMhnflz3ZYk1C9BVw/13OJa/roinbLq\nBuJ7BfPQzQkE+Lb9KHwdvY8Xklubz2u7/0JsUG+eGvIIAN9n/8gP2T8S6hPCNREjCPc10s0vnMK6\nM7yf/ne8PLx4esgjl3QqmN1hZ03ORjbm/UyDzYK/p46xUaP5KX87JmsdTwx6kL7BMa56mU6xpeAX\nlh1b0XT5usirmfJvB9/B2c3qNY2mC27luFyN9kbe3LeInNo8buo9gTOWIvYUHGRirxQm9R5/weUU\n5WyYnqzKxlvjha/GF1+NN4fKMtlZtBd/Tx0PDJhx0fP1zdZ6/vTL/9Fgt/DC8Gebvb4tBTtYduxr\nAHw0Pgw2JDI0bBCxQb2bjkGw2q28tHMhlZYq/nv4M4T5/mv0zYqGSubvepN6Wz2JIf15aMC9Fzx2\n4XjlSdKOfdNsV0zfoBjuS5jWbIuRQ3FQYDqD3jsYvxa2DHTWz3Vbk1C/BF051AtKTby6ZB91DTZu\nGtWLKVdHu222tbbuY3Z1DqE+Ifhrz5034HjlSb7LWkOUfyR39p1yRUf+f5jxOftLDvH4wFnEh/QD\nzgbBqux1rDm94Zz7e6o9+d3gB+kd2Ouyns87QMXyA2vYnLeNBnsDAFP7TGZcj2sv+zW0FUVR+OLY\nCo5WHGdav9ua+tVWqi21/N+et6m0nN0a0TcohicGP3hZa6mKovBTwXa+OrESgNtjb2ZU92Hn3fUB\nsPz4t2zO38ZNvW/ghl7jzrn9YOlh1CoV/fV90VzgMfaXpPNhxmIGhMbzSNJvgbM/9t7av4is6tMY\nfEIorS9nRHgy0/vf0ex9XWWp5puTP7C7eD8qVFwdMYJxUdfw9cnvOVR2GD+NL9PibsNTreFQ6WEO\nlWVistahUWsYZEhkdPdhxAadeyZGR/5+bE8k1C9BVw31kkozC5bso9rUyP03xnHNwO5uract+/jr\nPmuNWsOwsMFcF3UN3XXhVDRUsuLk9+wvOdR039/E3cGo7led8xiHSg+TV1tAbHAM0YE9z/tlXWwu\n5aVfXidS1405Vz15zhdeibmMQtMZztSVUGQupqbRxISe152zqfdS/NpHs9XMzwU7ABUTel4npyS2\nUqGpiIV7/4aXp5Y5Q5+84gPPTlRm8WHG55isdahVarr7hRPlH0G4n5FqSw1FdSWcqSum0lKF0TeU\nucN+f8HgvxhFUXhz/3ucrMrmiUEPEqeP5ftT6/jh9HoGG5OYHncHf9n/Pjm1eU0HJVrsjazP2cz6\n3J9odFjp4R/JtH630jMgqukxtxT8woqTK7E6/nWshr9WR399X3Jq8ig2n51vw+ATwmBjErFBvekd\n2Atvjddlf64VReH77HVsL9zNbbGTSQ4bdFk96Swk1C9BVwz1ipoGXl2yj7LqBu6+PpbUq6LcXVKb\n9fFg6WE+SP87Ok8/vDVelNaXAxATGE1ubT5Wh5XogB6k9ryOxUf+gc1h4/mrfke4X1jTY+wp2s+n\nmcuajqT2VHvSJyiaOH0sQ4xJ6L3PbjpdcuRLtp/ZxazE6QwxJrn8tUHHfD+2N9WWGoyhAVic1MaK\nhkrW5/5ETk0+BabCZuEIEKgNoLsunCkxNxLlH3FFz5Vbk8//7nmb7rpwbo+9mb/sf59g7yD+66qn\n8PX0obbRxJ/3/Y0ScxkjuiVzpPwY1Y21BGj9mdx7PCO7XXXeLROFpiLW5mwk2CuIJEMCvQKiUKvU\nKIpCVvVpthfuYl/JwabXplapifKP4KqoAfTX9W/2+bkYh+Ig7fg3bC34pem6ayJGMrXP5POedvgr\ns9XM5vxt9A3uc97dHcV1Jfxwej0NNgshPmfHLwj11tMrsAcB2nNDrtpSy4qTKzldk4fBJwSjbygG\nn1BCvIPx1nifPS3TQ4ufp99lj/HQWhLql6CrhXpNXSOvLd3HmXIzt14TzU2j28fY3G3Rx5yaPN7Y\n9x4q4KkhjxDlH0FG2RE25m3hRNUp/D113NJnIsPCh6BWqTlQks4HGYvp7hfOc8lPoPXw5EBJOh8d\nXoJWrWVq7GQKTUUcrTzBmbripufpHdiLpNB4Vp5aS4h3MC+MePayDzS6VB3t/dheuaqPdoedInMJ\nxeZSgrwCCfc14uvp49TnWHzkH/xy5v+3d+cBUZZ7w8e/s7AzAgKDgOBCIoKAgmKGmpla2m4n9XTM\n1mObT72Vpzy8lpUnszJP+1On9H06ZkUZlc+pjpYn28S9QHEFRZFlYFgGGLZZ7vcPa9QEFJ1hWH6f\nv5h77pn7d/+c8TfXdV/3de3AQ63FarfxUMq9xAQOdDxf2VjNiztfx9RSi4fag8nRE5gcPfGCBzs2\nWZsoMB0lv+Ywh6oPc3g3EpUAACAASURBVLSuyHEbYKR/OKn6ZIaHDEPvG9pmb4TNbuOf+zLZYfiF\nSP9wZsZeT+aBTykxlxHlH8Gdw29p9RbCorpi3t69msqmKgASQ+K5LmYa4X5hNFmb+KpwI98W/djq\nXRxalYaLI0YzJfrSE4MOFYXs0u1k5X9Bo7URH603jdamds89yCuQgQHRDOwTRT9fPTXNJsobjZQ3\nGDFbGpg6YCKJIfEdTSkA+yoPEhEaTIDdebdOSlFvR3f6T9Rqs7NszS4Ol9Ry5Zhobpp47rORuZqr\n82hsrGL5jteot5i5O+nWM75gVU3V+Hn44fW7kcEfHviUH4qzGR85luHBcfxj9z/RqDX814g/M/iU\n+7JNzXXsNuax05DDoZrDjlb8zXE3kh7ReasFdqfPY1fWnfNoaq7lyS3P02Jr4epBU5k2aPIZ+xga\nKthp+IWx4aPP646Ic9FkbeaY5Qj/ObSFvZUHHAVVrVIT6hNCuJ+eUJ8QArz6EODVhz6eOr45tond\nxn0M6jOA+5Jvx9fDlxZbCx8f/JzNpdvx1ngxJnwUaf1GMkAXhUqlYnPJdjIPforVbmVi/3SK6koo\nMB1BhYoUfRL5NYcxtdQR7B3EjCHXEBs4GGNTFcbGKsobjGSXbsfYWIlapSZVn4ypuZaDNQV4a7y4\nLmY64yLH0GJrobzRSEWDkaqmGpptLTT/OtVxbUsthbVF1FvMbeZChYqZsdd1+I4Ng7mcv21bQWJY\nHPPib7uQf47TSFFvR3f68q/ZcJCNu44zNiGMu67uWkundiSP9RYzZeZyYgIGntM5VDZW83rOSgwN\n5R2+FarFZuGFHa9SYi5Do9KgVqm5P/kOhrQzkrym2cTP5bsxNddy9eCpbQ5scoXu9Hnsyrp7HnMr\n8jhSe4xrBl/Rab1ErTl1jEdORR6HTUcpazBQaja02fqNCxrCvKRbz/iBvbV0J1n5/3IUT71vCHqf\nUPZU7sNH68Ot8bNIDIlHURT2VO7js4KvKDMb8FBrmTLgMqZET2x13gCb3cbP5bmsP/otJeYy4ERL\nf1bs9ef8g0dRFKqaqimsPUZ5g5Eg70D0vqHofUIwNlXyZs7/UGep5/LoCVwfMx21Sk2TtZlcYx65\nFXmMCU9ttSX/9u5/8kvFHh5Jn8dgr4vOKZZzIUW9Hd3ly791r4G31uURGerHoltG4eV5btNxdpZT\n85hfc4RScxmp+hGndU2e6BbbwWf5X2C2NnB59ARuiLmqzcJuV+z8WLyVzwq+oNnWwuXRE5hx0dUd\njq3MbOC57a9gR+GepNsY1jf2/E6yE3SXz2NXJ3l0jrbyqCgKtS11VDRWUttSh6m5ltqWOnw03lwW\nPb7d7vl9VQfZVraLXGMeFruVKF0kdw2/5YxZGu2KnbzK/UT4hZ/TLZB2xc6+qoMoikJCcJxTGz3G\nxkreyFmFoaGCpJAEvDRe5Bj30GJrAcBb48Vf0x467RwOmwp5cecbDOozgGVXPobRWO+0eKSot6M7\nfPlLjGaWvLsDVPDEraMID3btoI7z8VseTc11v96v24SnxpO0filM7J+OCvjgQBb5NUfw0nji7+FP\nZVMVl4Sn8ce4GWe0RsobjLy/fy2Hag7jo/XhpiHXktYv5by/qMX1pahQEeHfzwln6zrd4fPYHUge\nncOVeWy0NlFSX0a0LrLdAXRdhdnSwD92v0t+zREAQnyCSQsbiafGk88KvmRwwED+z8i70ag1KIrC\nil3/zWFTIQ+l3MvYIUmy9Ko4obnFxhuf7aHZYuOe6xI6vaDbFTtZ+f9CrVKTHDKcQQHR7XYHZuX/\nL022Jkbqkyg0HePH4i38WLzFMfd2cuhwbhpyLVq1ltdzVrK5dBuNtiZui5+NChX7qw+x05DDrvJc\nLHYLySEJzBp6AwFefS7oPLrjmuBC9GQ+Wu/TBgB2dX4evswf8We2lO4g0j+cQX2iUalUKIrCsbrj\n7CrPZcPRb5k2aDK5xr0cNhWSFJJw1omLnE2KehdmtdlZ+cVeSoxmJqf2J23Yud9W4iy7DDl8W/Qj\nABuPfY/Ow5/EkHjGR15MdJ/+p+27v+oQOwy/MEAXxR0JN6MoCrsr9/Hd8c2YLWauGjSV5NAEx/4P\njpzHf+f8Dz+X51LeUEFNkwmztQGAYO8gro2ZRqo+uUuNHRBC9F4eai3jIy8+bZtKpeKPQ2dw2HSU\nLwu/YWjfi/i84CtUqLgu5spOj1GKehdV32jh9azdHCiqYUj/AGZOct4gi3NlV+x8WbgRtUrNnLib\nKDAdIbdiL5tLt7GtbCdz42eR+uukEhabhcyDn6JCxey4G0605lUwInQ4I0KHt/r+Plof5o+4k7f3\nrGZv5QH6eOqY2D+d1LARjl/BQgjR1fl6+HJr/Cxe+fltXv35bVrsFtIj0jp0f7+zSFHvggxVDbz0\ncQ6G6kZSh4Zy19XxblkTfZchB0NDOZeEj2ZMeCpjwlOZPdTObuM+/rn3Q1blvU9lUzVToify+f6v\nKW8wMrF/OtG6/md/8195ajy5N+l2Ss0Gwv3C3DrSVwghzlds0EVMjr6Ur49twkPtwfRBU9wShxT1\nLubAsWpey9qNucnK9IsHMOPSwajd0GI9tZV+xSlzWatVapJDE3g49T7eyFnF5wVfUVxfSk7FHgI8\ndVw9+IoOH0utUss1byFEt3f14KnUttRxUeCgNpdcdjUp6l3IwaIaVnyUg92ucPv0OMYnuW8+913l\nuRgayhkbPrrV5UMj/cP5y6j5vJGzih2GXwC4cci1+Gi9OztUIYToErRqLXPjZ7k3BrceXTgcL6/n\n5bW52O0K/3VjIkkxIS47lqm5rt2FLuyKna+OfINapW51xanfBHoF8HDKvWQe/IxAP/9Omx9dCCFE\n66SodwHGmkZe/OgXGput/PmaeJcVdJvdRubBT/mpZBvpEWnMir2h1XWZd5XnUtZOK/1U3lpvbo2f\nLfcFCyFEFyBF3c1qG1p48aMcTPUtzJ50EWMTXDM5SpO1iXf2vMe+qoNoVBp+KtmGqbmWO4bPOW06\nx3qL+Zxa6UIIIboeKepuZLHaePnjXAxVDUy7OJqpadEuOU5Ns4k3clZRXF9KQnAcf4r7A6v3fcSe\nyv28vOst7k2+HZtiY+Ox7/mxZCstthbSI9LO2koXQgjRtbi0qC9dupScnBxUKhUZGRkkJZ285lpa\nWsrDDz+MxWIhPj6ep59+mq1bt/Lggw8yZMgQAGJjY3n88cddGaJbffLdYY6U1nLJ8H784dK2Fxjp\niL2VB/hP0Q/AiXXCPdRaCkyF1DSbGBd5MTOHXIdGreHepNtZs38tW8t2snTb3zFbGrApNgK9Arh2\n8JWM+90EC0IIIbo+lxX1bdu2cfToUTIzMykoKCAjI4PMzEzH88uWLeOOO+5gypQpPPXUU5SUlACQ\nlpbGK6+84qqwuoy8I1Vs2F5Ev76+3HLFUKdMtHKs9jj/2P1PLHbLadtVqLg+ZjqToy91HEej1nDL\nsJkEeQfy78KNhPoEM3XAZaT1S+nUVcmEEEI4j8v+987Ozmby5BPrAMfExGAymaivr8ff3x+73c7O\nnTtZsWIFAIsXLwagqKjIVeF0KfWNFlZ+sReNWsW8a+Px8rjwFddqmk28tftdrHYrdyfeyrC+sVjs\nFix2K1q1Fj8P3zNeo1KpuGbwFaRHpBHoFSATvwghRDfnsqJuNBpJSDg5z3ffvn2pqKjA39+fqqoq\n/Pz8ePbZZ8nLy2PUqFE88sgjAOTn53PPPfdgMpmYP38+6enp7R4nKMgXrfbCimJ7K944m6IovP3u\ndmrqW5g7fRijEyMv+D1brC2s+PY9appNzEm+gcvjOtZ1Hopzzr8z89iTSR6dQ/LoHJJH5+isPHZa\nP+upK7wqioLBYGDu3LlERkYyb948Nm3axLBhw5g/fz7Tpk2jqKiIuXPnsmHDBjw9Pdt83+rqhguK\nq7Nvxfo+p4Ts3aXERgUyYXi/Cz62oij8v7z3Kag6yph+qVzc92K33Fomt7Q5h+TROSSPziF5dA5n\n59EtS6/q9XqMRqPjcXl5OaGhoQAEBQURERFBdPSJ0d5jx47l0KFDTJw4kenTpwMQHR1NSEgIBoOB\nqKgoV4XZqYor6vngm0P4eGn589XxqNXndx1dURTKGso5UJXPnsp97Ks6yOCAgfwx7kZZBEUIIXox\nl11ETU9PZ/369QDk5eWh1+vx9/cHQKvVEhUVRWFhoeP5QYMGsW7dOlauXAlARUUFlZWVhIV1/io3\nrlDX0MLLa3Nptti4bVocwQHnN53q1tKd/N+f/sbftr7Ix4c+Z1/VQaJ0kcxLnIuHDHATQohezWVV\nICUlhYSEBGbPno1KpWLx4sVkZWWh0+mYMmUKGRkZLFy4EEVRiI2NZdKkSTQ0NLBgwQI2btyIxWLh\nySefbLfrvbuw2uy8/ukejKYmrrlkIKPj9K3u12htYuOx74jwD291ylWL3crHh9Zhs1tJ1ScT13cI\nQ4MuItinr6tPQQghRDfg0qbdggULTnscFxfn+HvAgAF88MEHpz3v7+/Pm2++6cqQOp2iKKxef4CD\nRTWkDg3luvGDWt0vr/IAH+z/hOrmGny0PgwPHoanxuO0ffZWHqDR2sikqPHcOOSazghfCCFENyL9\ntS729fYifsgtJTrMn7uuij9jGdUGSwOfHPoXW8p2oFapidZFcqyumJyKPYzuN/K0fXf+uhra6LDT\ntwshhBDgwmvqAvYcriTz23wC/Dx54MYkvDxPv/WuxWbhue2vsKVsB1G6SB4b9QC3J9wMwObS7aft\n22RtIte4F71vCFG6C78NTgghRM8jLXUXMVQ38ObneWjUKubfmEjfPmcOjNtbuR9jUxVj+qXyp7g/\nOFZMuyhwEAer8zE2VhHy6/XyXONeLHYLo/QjZIS7EEKIVklL3QUam628+sluGpqtzL0ijpiIgFb3\n21WeC8BlUeNOWwJ1bPhoALac0lrf8WvX+6iwEa4KWwghRDcnRd3J7IrCO//aS4nRzOTU/oxLCm91\nvxabhd2V+wjxCaa/f8Rpz43UJ+Gt8SK7dAd2xU59i9lx61qYX+sj54UQQggp6k627scj/HzIyLAB\nQcycdFGb++2t3E+LrYUUfdIZ3eleGk9Sw0ZQ02xif9Uhfq7Ixa7YpZUuhBCiXVLUnSivsIp1PxUS\nEuDNPdcloNW0nd7fut5H6hNbff63LvjNpdvZXvYLKlSk6pOdH7QQQogeQwbKOYnNbufDbw6hAu67\nYTg637YnzXF0vXv3Jcq/9ZHsA/tEEe4XRm5FHjbFxpDAwQR5B7ooeiGEED2BtNSd5IecUoqNZsYn\nhzOwX592991bdYAWWwsjW+l6/41KpWJs+Ghsig2QAXJCCCHOToq6EzQ2W/n0h8N4eWi4Yfzgs+7/\n869d761NBXuqtH4paFQa1Co1I9rophdCCCF+I93vTvBF9lHqGizcMGEwAf5eju3Gxio+PJBFqj6Z\nsREnrpG32CzkGvee6Ho/yyQyOk9/ZsZeh4KCv4efS89BCCFE9ydF/QIZaxrZsL2Ivn28uGL0ySVi\n7Yqd1fsyya85wr6qgxw2FXJT7PUnu94j2+56P9W4yItdGb4QQogeRIr6BVr7XQFWm50bL43B0+Pk\nBDKbjv9Efs0RhvWNpd5iZnPpdorqivH7tcV9tq53IYQQoqOkqF+AgmIT2/aVMyhcx5j4k+u+G8zl\nrCv4Cn8PP26Nn423xouPD33OTyXbAAg+h653IYQQoqNkoNx5UhSFT74rAGDWpCGO1ddsdhur932E\nxW5l1tAb0Hn646Hx4Oa4PzBn2Ey8Nd5M7H+JzN8uhBDC6aSlfp72Hq1m/7EaEgcHExt18v7xjce+\n50jtMUaFjTiji31s+CjG9EtBhRR0IYQQzidF/TwoikLWd4cBmDHh5C1sZWYDXxzZQB9PHTNjr2/1\ntWqVdI4IIYRwDakw5yEnv5IjpbWkDg1lQD+dY/u/C/+DVbExK/Z6/Dx83RihEEKI3kiKegfZFYWs\n7w+jAq4fN8ixvbKxmp3lOUT49SM5dLj7AhRCCNFrSVHvoB37yzleUc/FCWFEhvo7tn9b9AN2xc7k\n6EtlEJwQQgi3kKLeATa7nU9/OIJapeK6U1rp9RYzP5VsJdArgNQwWUlNCCGEe0hR74DsPQYMVQ2M\nSwpHH3TymvkPx7fQYrdwedR4tGoZeyiEEMI9pKifI6vNzrqfjqDVqLg2faBje4vNwqbjP+Kj9eGS\niDT3BSiEEKLXk6J+jn7ILcVoauLSEZH07ePt2L6ldAf1FjMTIsfirfVu5x2EEEII13JpX/HSpUvJ\nyclBpVKRkZFBUtLJyVhKS0t5+OGHsVgsxMfH8/TTT5/1Ne5isdr41+ZCPLVqrho7wLHdrtjZeOw7\ntGotl/ZPd2OEQgghhAuL+rZt2zh69CiZmZkUFBSQkZFBZmam4/lly5Zxxx13MGXKFJ566ilKSko4\nfvx4u69xl02/lFBd38jw0fWsOrCKFnsLFruVZmsz1c01pEeMIcBLd/Y3EkIIIVzIZd3v2dnZTJ48\nGYCYmBhMJhP19fUA2O12du7cyaRJkwBYvHgxERER7b7GXZparPzvni14J/1IAZs5bCrE0FBBXUsd\nCgr9/SOYOuAyt8YohBBCgAtb6kajkYSEBMfjvn37UlFRgb+/P1VVVfj5+fHss8+Sl5fHqFGjeOSR\nR9p9jTtUNFTyyrbV2KJLUKNmQv90pg+cjL+nn1viEUIIIdrTafdfKYpy2t8Gg4G5c+cSGRnJvHnz\n2LRpU7uvaUtQkC9areas+7UnNLT1rvOV371Hlb0ETGH87fo7GaKPuqDj9HRt5VF0jOTROSSPziF5\ndI7OyqPLirper8doNDoel5eXExoaCkBQUBARERFER0cDMHbsWA4dOtTua9pSXd1wQXGGhuqoqKhr\n9bm8sgKUFi+m6WcQqApscz/Rfh7FuZM8Oofk0Tkkj87h7Dy29wPBZdfU09PTWb9+PQB5eXno9XpH\nN7pWqyUqKorCwkLH84MGDWr3NZ2tutFEM2ZoDGDyKGmhCyGE6Ppc1lJPSUkhISGB2bNno1KpWLx4\nMVlZWeh0OqZMmUJGRgYLFy5EURRiY2OZNGkSarX6jNe4y4/5+wHo7x+Jj5fMEieEEKLrc2m1WrBg\nwWmP4+LiHH8PGDCADz744KyvcZcdxw6BD6QNHOLuUIQQQohzIjPKtcJU34yhyQBAapQUdSGEEN2D\nFPVW/LSnDJWvCS+VL4FefdwdjhBCCHFOpKj/jqIobNp9BLVXE4MC+sva6EIIIboNKeq/c7CohipL\nOQADA2XUuxBCiO5DivrvfJ9TgtrPBEC0LtLN0QghhBDnTor6KcxNFnYcqMAn0AxAlBR1IYQQ3YgU\n9VNsyTNgsdrx7FOPv4cfQV6B7g5JCCGEOGdS1E+x72g1Gg8rDUotUbpIGSQnhBCiW5GifoqbLovh\n5mv0gHS9CyGE6H6kqJ8iLMgXq1cNIEVdCCFE9yNF/XeK6ooBiNb1d3MkQgghRMdIUf+dorpifLQ+\nBHsHuTsUIYQQokOkqJ+i0dpEeaNRBskJIYTolqSon+K4o+tdrqcLIYTofqSon+K36+kySE4IIUR3\nJEX9FMekpS6EEKIbk6J+Ci+NJ3rfEEJ8gt0dihBCCNFhWncH0JXMGnoDAGqV/NYRQgjR/UhRP4UU\ncyGEEN2ZVDEhhBCih5CiLoQQQvQQUtSFEEKIHkKKuhBCCNFDSFEXQggheggp6kIIIUQP4dJb2pYu\nXUpOTg4qlYqMjAySkpIcz02aNIl+/fqh0WgAWL58OYWFhTz44IMMGTIEgNjYWB5//HFXhiiEEEL0\nGC4r6tu2bePo0aNkZmZSUFBARkYGmZmZp+3z9ttv4+fn53hcWFhIWloar7zyiqvCEkIIIXosl3W/\nZ2dnM3nyZABiYmIwmUzU19e76nBCCCFEr+eylrrRaCQhIcHxuG/fvlRUVODv7+/YtnjxYoqLi0lN\nTeWRRx4BID8/n3vuuQeTycT8+fNJT09v9zhBQb5otZoLijU0VHdBrxcnSB6dQ/LoHJJH55A8Okdn\n5bHTpolVFOW0xw888ADjx48nICCA+++/n/Xr1zNy5Ejmz5/PtGnTKCoqYu7cuWzYsAFPT88237e6\nuuGC4goN1VFRUXdB7yEkj84ieXQOyaNzSB6dw9l5bO8HgsuKul6vx2g0Oh6Xl5cTGhrqeHz99dc7\n/p4wYQIHDx7kyiuvZPr06QBER0cTEhKCwWAgKiqqzeM449eP/BJ1Dsmjc0genUPy6BySR+forDy6\n7Jp6eno669evByAvLw+9Xu/oeq+rq+POO++kpaUFgO3btzNkyBDWrVvHypUrAaioqKCyspKwsDBX\nhSiEEEL0KC5rqaekpJCQkMDs2bNRqVQsXryYrKwsdDodU6ZMYcKECcyaNQsvLy/i4+O58sorMZvN\nLFiwgI0bN2KxWHjyySfb7XoXQgghxEkq5fcXu4UQQgjRLcmMckIIIUQPIUVdCCGE6CGkqAshhBA9\nRKfdp94VtTc3vWjf888/z86dO7Fardx9990kJiby6KOPYrPZCA0N5YUXXpBBjueoqamJq6++mvvu\nu4+xY8dKHs/DunXreOedd9BqtTzwwAMMHTpU8thBZrOZxx57DJPJhMVi4f777yc0NJQnn3wSgKFD\nh/LUU0+5N8gu7ODBg9x3333cdtttzJkzh9LS0lY/g+vWrePdd99FrVYzc+ZMbrrpJucGovRSW7du\nVebNm6coiqLk5+crM2fOdHNE3Ud2drZy1113KYqiKFVVVcqll16qLFy4UPnyyy8VRVGUF198UVmz\nZo07Q+xWVqxYocyYMUP55JNPJI/noaqqSpk6dapSV1enGAwGZdGiRZLH87B69Wpl+fLliqIoSllZ\nmXLFFVcoc+bMUXJychRFUZSHH35Y2bRpkztD7LLMZrMyZ84cZdGiRcrq1asVRVFa/QyazWZl6tSp\nSm1trdLY2KhcddVVSnV1tVNj6bXd7zI3/fkbPXo0L7/8MgB9+vShsbGRrVu3cvnllwNw2WWXkZ2d\n7c4Qu42CggLy8/OZOHEigOTxPGRnZzN27Fj8/f3R6/UsWbJE8ngegoKCqKmpAaC2tpbAwECKi4sd\nPZiSx7Z5enry9ttvo9frHdta+wzm5OSQmJiITqfD29ublJQUdu3a5dRYem1RNxqNBAUFOR7/Nje9\nODuNRoOvry8Aa9euZcKECTQ2Njq6N4ODgyWX5+i5555j4cKFjseSx447fvw4TU1N3HPPPdx8881k\nZ2dLHs/DVVddRUlJCVOmTGHOnDk8+uij9OnTx/G85LFtWq0Wb2/v07a19hk0Go307dvXsY8r6k6v\nvqZ+KkVu1++wb775hrVr17Jq1SqmTp3q2C65PDefffYZI0aMaHMaZMnjuaupqeG1116jpKSEuXPn\nnpY7yeO5+fzzz4mIiGDlypXs37+f+++/H53u5NSmksfz11buXJHTXlvUzzY3vWjfDz/8wJtvvsk7\n77yDTqfD19eXpqYmvL29MRgMp3VDidZt2rSJoqIiNm3aRFlZGZ6enpLH8xAcHMzIkSPRarVER0fj\n5+eHRqORPHbQrl27GDduHABxcXE0NzdjtVodz0seO6a173JrdWfEiBFOPW6v7X5vb2560b66ujqe\nf/553nrrLQIDAwG45JJLHPncsGED48ePd2eI3cJLL73EJ598wkcffcRNN93EfffdJ3k8D+PGjWPL\nli3Y7Xaqq6tpaGiQPJ6HAQMGkJOTA0BxcTF+fn7ExMSwY8cOQPLYUa19BpOTk9m9eze1tbWYzWZ2\n7drFqFGjnHrcXj1N7PLly9mxY4djbvq4uDh3h9QtZGZm8uqrrzJo0CDHtmXLlrFo0SKam5uJiIjg\n2WefxcPDw41Rdi+vvvoqkZGRjBs3jscee0zy2EEffvgha9euBeDee+8lMTFR8thBZrOZjIwMKisr\nsVqtPPjgg4SGhvLEE09gt9tJTk7mr3/9q7vD7JL27NnDc889R3FxMVqtlrCwMJYvX87ChQvP+Az+\n+9//ZuXKlahUKubMmcO1117r1Fh6dVEXQgghepJe2/0uhBBC9DRS1IUQQogeQoq6EEII0UNIURdC\nCCF6CCnqQgghRA8hRV0I4TJZWVksWLDA3WEI0WtIURdCCCF6iF47TawQ4qTVq1fz1VdfYbPZGDx4\nMHfddRd33303EyZMYP/+/QD8/e9/JywsjE2bNvH666/j7e2Nj48PS5YsISwsjJycHJYuXYqHhwcB\nAQE899xzANTX17NgwQIKCgqIiIjgtddeQ6VSufN0heixpKUuRC+Xm5vL119/zZo1a8jMzESn07F5\n82aKioqYMWMG77//PmlpaaxatYrGxkYWLVrEq6++yurVq5kwYQIvvfQSAH/5y19YsmQJ7733HqNH\nj+a7774DID8/nyVLlpCVlcWhQ4fIy8tz5+kK0aNJS12IXm7r1q0cO3aMuXPnAtDQ0IDBYCAwMJDh\nw4cDkJKSwrvvvkthYSHBwcH069cPgLS0ND788EOqqqqora0lNjYWgNtuuw04cU09MTERHx8fAMLC\nwqirq+vkMxSi95CiLkQv5+npyaRJk3jiiScc244fP86MGTMcjxVFQaVSndFtfur2tmac1mg0Z7xG\nCOEa0v0uRC+XkpLC999/j9lsBmDNmjVUVFRgMpnYu3cvcGJZzqFDhzJw4EAqKyspKSkBIDs7m+Tk\nZIKCgggMDCQ3NxeAVatWsWbNGveckBC9mLTUhejlEhMT+dOf/sQtt9yCl5cXer2eMWPGEBYWRlZW\nFsuWLUNRFFasWIG3tzfPPPMMDz30kGP992eeeQaAF154gaVLl6LVatHpdLzwwgts2LDBzWcnRO8i\nq7QJIc5w/Phxbr75Zr7//nt3hyKE6ADpfhdCCCF6CGmpCyGEED2EtNSFEEKIHkKKuhBCCNFDSFEX\nQggheggp6kIIDX+sxQAAABlJREFUIUQPIUVdCCGE6CGkqAshhBA9xP8Hatzepd0Tr8IAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss: 1.7077101719856262\n",
            "validation accuracy: 0.6749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yStGz6FcV-dm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fourth Architecture Training and Validation set"
      ]
    },
    {
      "metadata": {
        "id": "wzJiwn7tVtEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4291
        },
        "outputId": "07a9e6de-bdef-409a-f414-97ce7d01059f"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 1.9756 - acc: 0.2536\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 434us/step - loss: 1.6698 - acc: 0.3781\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 18s 440us/step - loss: 1.5551 - acc: 0.4241\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 436us/step - loss: 1.4763 - acc: 0.4566\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 434us/step - loss: 1.4206 - acc: 0.4804\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 433us/step - loss: 1.3715 - acc: 0.5010\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 429us/step - loss: 1.3262 - acc: 0.5193\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 18s 439us/step - loss: 1.2833 - acc: 0.5367\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 18s 440us/step - loss: 1.2414 - acc: 0.5525\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 433us/step - loss: 1.2159 - acc: 0.5623\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 19s 466us/step - loss: 1.1068 - acc: 0.6052 - val_loss: 0.9934 - val_acc: 0.6529\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 1.0681 - acc: 0.6183 - val_loss: 0.9930 - val_acc: 0.6544\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 1.0365 - acc: 0.6322 - val_loss: 0.9692 - val_acc: 0.6536\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 1.0105 - acc: 0.6408 - val_loss: 0.9422 - val_acc: 0.6680\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.9838 - acc: 0.6498 - val_loss: 0.9267 - val_acc: 0.6742\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.9563 - acc: 0.6604 - val_loss: 0.8718 - val_acc: 0.6896\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.9404 - acc: 0.6648 - val_loss: 0.8606 - val_acc: 0.6956\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 0.9155 - acc: 0.6732 - val_loss: 0.8491 - val_acc: 0.7015\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.9003 - acc: 0.6797 - val_loss: 0.8309 - val_acc: 0.7087\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.8743 - acc: 0.6885 - val_loss: 0.8257 - val_acc: 0.7096\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.8658 - acc: 0.6961 - val_loss: 0.8050 - val_acc: 0.7198\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.8470 - acc: 0.6987 - val_loss: 0.7898 - val_acc: 0.7209\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.8324 - acc: 0.7046 - val_loss: 0.7896 - val_acc: 0.7232\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.8180 - acc: 0.7092 - val_loss: 0.7610 - val_acc: 0.7308\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.8007 - acc: 0.7137 - val_loss: 0.7537 - val_acc: 0.7345\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.7885 - acc: 0.7200 - val_loss: 0.7309 - val_acc: 0.7407\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.7704 - acc: 0.7246 - val_loss: 0.7300 - val_acc: 0.7408\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.7616 - acc: 0.7296 - val_loss: 0.7177 - val_acc: 0.7491\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.7530 - acc: 0.7318 - val_loss: 0.7099 - val_acc: 0.7473\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.7412 - acc: 0.7385 - val_loss: 0.6943 - val_acc: 0.7525\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 0.7265 - acc: 0.7414 - val_loss: 0.6883 - val_acc: 0.7566\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.7157 - acc: 0.7451 - val_loss: 0.6880 - val_acc: 0.7571\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.7013 - acc: 0.7536 - val_loss: 0.6743 - val_acc: 0.7593\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 0.6973 - acc: 0.7541 - val_loss: 0.6932 - val_acc: 0.7566\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.6903 - acc: 0.7542 - val_loss: 0.6532 - val_acc: 0.7701\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.6746 - acc: 0.7633 - val_loss: 0.6700 - val_acc: 0.7627\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 0.6625 - acc: 0.7665 - val_loss: 0.6453 - val_acc: 0.7740\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.6527 - acc: 0.7702 - val_loss: 0.6554 - val_acc: 0.7683\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.6484 - acc: 0.7704 - val_loss: 0.6510 - val_acc: 0.7671\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.6384 - acc: 0.7755 - val_loss: 0.6856 - val_acc: 0.7585\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.6322 - acc: 0.7756 - val_loss: 0.6230 - val_acc: 0.7809\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.6175 - acc: 0.7788 - val_loss: 0.6203 - val_acc: 0.7850\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.6154 - acc: 0.7802 - val_loss: 0.6185 - val_acc: 0.7836\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.6029 - acc: 0.7876 - val_loss: 0.6010 - val_acc: 0.7890\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 18s 455us/step - loss: 0.5967 - acc: 0.7873 - val_loss: 0.6182 - val_acc: 0.7832\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.5850 - acc: 0.7933 - val_loss: 0.6006 - val_acc: 0.7875\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.5801 - acc: 0.7947 - val_loss: 0.5886 - val_acc: 0.7905\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.5705 - acc: 0.7977 - val_loss: 0.5782 - val_acc: 0.7969\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5652 - acc: 0.7995 - val_loss: 0.6034 - val_acc: 0.7896\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5579 - acc: 0.8039 - val_loss: 0.5814 - val_acc: 0.7937\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5527 - acc: 0.8048 - val_loss: 0.6024 - val_acc: 0.7884\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.5467 - acc: 0.8043 - val_loss: 0.5712 - val_acc: 0.8008\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5435 - acc: 0.8078 - val_loss: 0.5787 - val_acc: 0.7974\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5341 - acc: 0.8122 - val_loss: 0.5707 - val_acc: 0.8008\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.5236 - acc: 0.8123 - val_loss: 0.5668 - val_acc: 0.8022\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.5167 - acc: 0.8172 - val_loss: 0.5735 - val_acc: 0.7998\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.5141 - acc: 0.8194 - val_loss: 0.5594 - val_acc: 0.8043\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.5108 - acc: 0.8188 - val_loss: 0.5556 - val_acc: 0.8047\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.5019 - acc: 0.8205 - val_loss: 0.5626 - val_acc: 0.8017\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4992 - acc: 0.8236 - val_loss: 0.5550 - val_acc: 0.8063\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4934 - acc: 0.8265 - val_loss: 0.5554 - val_acc: 0.8029\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 18s 455us/step - loss: 0.4846 - acc: 0.8262 - val_loss: 0.5482 - val_acc: 0.8087\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4858 - acc: 0.8279 - val_loss: 0.5505 - val_acc: 0.8066\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.4750 - acc: 0.8291 - val_loss: 0.5616 - val_acc: 0.8084\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4737 - acc: 0.8295 - val_loss: 0.5558 - val_acc: 0.8084\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.4667 - acc: 0.8331 - val_loss: 0.5514 - val_acc: 0.8076\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.4633 - acc: 0.8336 - val_loss: 0.5591 - val_acc: 0.8065\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4614 - acc: 0.8354 - val_loss: 0.5450 - val_acc: 0.8086\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4520 - acc: 0.8383 - val_loss: 0.5492 - val_acc: 0.8105\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4452 - acc: 0.8425 - val_loss: 0.5465 - val_acc: 0.8106\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4427 - acc: 0.8418 - val_loss: 0.5312 - val_acc: 0.8141\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4354 - acc: 0.8441 - val_loss: 0.5488 - val_acc: 0.8111\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4324 - acc: 0.8443 - val_loss: 0.5266 - val_acc: 0.8174\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.4270 - acc: 0.8480 - val_loss: 0.5366 - val_acc: 0.8139\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4235 - acc: 0.8481 - val_loss: 0.5375 - val_acc: 0.8153\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.4274 - acc: 0.8466 - val_loss: 0.5288 - val_acc: 0.8205\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4196 - acc: 0.8501 - val_loss: 0.5512 - val_acc: 0.8139\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.4118 - acc: 0.8525 - val_loss: 0.5330 - val_acc: 0.8148\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.4150 - acc: 0.8526 - val_loss: 0.5216 - val_acc: 0.8171\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.4108 - acc: 0.8528 - val_loss: 0.5280 - val_acc: 0.8218\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.4026 - acc: 0.8559 - val_loss: 0.5242 - val_acc: 0.8174\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3981 - acc: 0.8588 - val_loss: 0.5288 - val_acc: 0.8173\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3924 - acc: 0.8615 - val_loss: 0.5303 - val_acc: 0.8192\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3878 - acc: 0.8598 - val_loss: 0.5252 - val_acc: 0.8191\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3932 - acc: 0.8585 - val_loss: 0.5191 - val_acc: 0.8220\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3849 - acc: 0.8630 - val_loss: 0.5311 - val_acc: 0.8182\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3814 - acc: 0.8623 - val_loss: 0.5267 - val_acc: 0.8209\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.3779 - acc: 0.8656 - val_loss: 0.5265 - val_acc: 0.8183\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3703 - acc: 0.8667 - val_loss: 0.5186 - val_acc: 0.8224\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.3654 - acc: 0.8691 - val_loss: 0.5241 - val_acc: 0.8244\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3660 - acc: 0.8700 - val_loss: 0.5271 - val_acc: 0.8241\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3667 - acc: 0.8683 - val_loss: 0.5247 - val_acc: 0.8213\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3643 - acc: 0.8694 - val_loss: 0.5286 - val_acc: 0.8226\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3581 - acc: 0.8727 - val_loss: 0.5317 - val_acc: 0.8189\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.3552 - acc: 0.8737 - val_loss: 0.5468 - val_acc: 0.8216\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 18s 455us/step - loss: 0.3521 - acc: 0.8724 - val_loss: 0.5324 - val_acc: 0.8211\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3481 - acc: 0.8757 - val_loss: 0.5279 - val_acc: 0.8258\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3456 - acc: 0.8748 - val_loss: 0.5148 - val_acc: 0.8256\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3450 - acc: 0.8759 - val_loss: 0.5224 - val_acc: 0.8248\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3406 - acc: 0.8768 - val_loss: 0.5223 - val_acc: 0.8264\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 18s 458us/step - loss: 0.3375 - acc: 0.8779 - val_loss: 0.5214 - val_acc: 0.8250\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3399 - acc: 0.8790 - val_loss: 0.5131 - val_acc: 0.8279\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3297 - acc: 0.8813 - val_loss: 0.5196 - val_acc: 0.8244\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3313 - acc: 0.8797 - val_loss: 0.5240 - val_acc: 0.8241\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 18s 461us/step - loss: 0.3260 - acc: 0.8830 - val_loss: 0.5221 - val_acc: 0.8273\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.3294 - acc: 0.8811 - val_loss: 0.5141 - val_acc: 0.8270\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 18s 459us/step - loss: 0.3260 - acc: 0.8825 - val_loss: 0.5262 - val_acc: 0.8258\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 0.3235 - acc: 0.8837 - val_loss: 0.5155 - val_acc: 0.8291\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 18s 456us/step - loss: 0.3202 - acc: 0.8852 - val_loss: 0.5152 - val_acc: 0.8272\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 18s 457us/step - loss: 0.3169 - acc: 0.8854 - val_loss: 0.5176 - val_acc: 0.8274\n",
            "Test loss: 0.5175829311609268\n",
            "Test accuracy: 0.8274\n",
            "[0.5175829311609268, 0.8274]\n",
            "{'val_loss': [0.9933675008773803, 0.9930291749954223, 0.9692492781639099, 0.9421755738258362, 0.9267167246818543, 0.8717749519348145, 0.8606060838699341, 0.8491495646476745, 0.830907308769226, 0.8257170621871949, 0.8050463391304016, 0.7897990587234497, 0.7896383337020874, 0.7609550484657288, 0.7537112248420715, 0.730883325958252, 0.7300317140579223, 0.717741630077362, 0.7098774179458618, 0.6942624966621399, 0.6882684016704559, 0.6879621248722076, 0.6743109189987183, 0.6931770641326904, 0.6531655465126037, 0.6700345139503479, 0.6453016425132752, 0.6554341370105743, 0.6510366500377655, 0.6856044441223145, 0.6229942685604095, 0.6202921012878418, 0.6184549376487732, 0.6010028290748596, 0.618198285484314, 0.6005977078437805, 0.5886427110671997, 0.578200103187561, 0.6033805073738098, 0.5813813999176025, 0.6024292815685273, 0.571227636384964, 0.5786816147327423, 0.5707113666534424, 0.5667620022296905, 0.5735442418575287, 0.5594427571773529, 0.5556275189876556, 0.5625841787815093, 0.5550008803844452, 0.5554419591426849, 0.5482299195289612, 0.5504948530673981, 0.5616242552757263, 0.5557900015354157, 0.5514305174350739, 0.559093464422226, 0.5450379321098328, 0.5491776026725769, 0.546463385438919, 0.5312238052845001, 0.5487594303131104, 0.5266086927890777, 0.5365547606945038, 0.5374520360946655, 0.5287860832214355, 0.5512318419456482, 0.5329867087364196, 0.521649558210373, 0.5279638134002685, 0.52416837849617, 0.528827658200264, 0.5302633712291718, 0.5251952585220336, 0.5190736099243164, 0.5310741328954697, 0.5267113508701324, 0.5264831098079681, 0.518576712179184, 0.5240979872226715, 0.5271287157535552, 0.5247364227771759, 0.5285813768863677, 0.5316531832695007, 0.5467581223011017, 0.5324011074066162, 0.5278611296892166, 0.5148131465435029, 0.5223690528392791, 0.5222834883451462, 0.5214335220336914, 0.5130667906761169, 0.5196220673799514, 0.5240112582206726, 0.5220943278074265, 0.5141188723087311, 0.5262330490589142, 0.515451891541481, 0.515178806591034, 0.5175829311609268], 'val_acc': [0.6529, 0.6544, 0.6536, 0.668, 0.6742, 0.6896, 0.6956, 0.7015, 0.7087, 0.7096, 0.7198, 0.7209, 0.7232, 0.7308, 0.7345, 0.7407, 0.7408, 0.7491, 0.7473, 0.7525, 0.7566, 0.7571, 0.7593, 0.7566, 0.7701, 0.7627, 0.774, 0.7683, 0.7671, 0.7585, 0.7809, 0.785, 0.7836, 0.789, 0.7832, 0.7875, 0.7905, 0.7969, 0.7896, 0.7937, 0.7884, 0.8008, 0.7974, 0.8008, 0.8022, 0.7998, 0.8043, 0.8047, 0.8017, 0.8063, 0.8029, 0.8087, 0.8066, 0.8084, 0.8084, 0.8076, 0.8065, 0.8086, 0.8105, 0.8106, 0.8141, 0.8111, 0.8174, 0.8139, 0.8153, 0.8205, 0.8139, 0.8148, 0.8171, 0.8218, 0.8174, 0.8173, 0.8192, 0.8191, 0.822, 0.8182, 0.8209, 0.8183, 0.8224, 0.8244, 0.8241, 0.8213, 0.8226, 0.8189, 0.8216, 0.8211, 0.8258, 0.8256, 0.8248, 0.8264, 0.825, 0.8279, 0.8244, 0.8241, 0.8273, 0.827, 0.8258, 0.8291, 0.8272, 0.8274], 'loss': [1.1067780641555787, 1.0680721851348878, 1.0365114644527436, 1.0104731387615205, 0.9837878919124603, 0.9563201537370681, 0.9404394294500351, 0.9155292484283447, 0.9003170318841934, 0.8742509103059769, 0.8657785773992538, 0.8469502332448959, 0.8324252573251725, 0.8180169223308563, 0.8007036271333694, 0.7884818892002106, 0.7703911253213882, 0.7616042803525924, 0.7530104167461396, 0.7412027613401413, 0.7264665300607681, 0.7157101265192032, 0.7013288331985473, 0.6973393630266189, 0.690333866906166, 0.6745785754680633, 0.6624940512418747, 0.652734670829773, 0.6484152735710144, 0.6384218994140625, 0.6321891409635544, 0.6174564909815788, 0.6153903010368347, 0.6029068863511086, 0.596715101659298, 0.5849859298110008, 0.5801261939167977, 0.5704669773221016, 0.565200225007534, 0.5579068713188171, 0.5527499204874039, 0.5466754892468453, 0.5435015148162842, 0.5341201362133026, 0.523553937113285, 0.5166690606236458, 0.514065024805069, 0.5108268654823304, 0.5019065637528897, 0.4992465308904648, 0.4933662063121796, 0.484648069190979, 0.4858391553461552, 0.4750002546131611, 0.47369566675424574, 0.46668418266773226, 0.4633323730409145, 0.46142269852161405, 0.45197175714969634, 0.4451985484600067, 0.44271509437561035, 0.4353504859864712, 0.4323719481110573, 0.42703695414066317, 0.4234716266691685, 0.42741026184558867, 0.41961841582655907, 0.4117811876356602, 0.41501938617825507, 0.4108179472506046, 0.4026347545027733, 0.3981383758068085, 0.3923892894089222, 0.3877938692808151, 0.39320196576714517, 0.38494089279174803, 0.3814442115455866, 0.3778575211644173, 0.37026535021066664, 0.36540879054665565, 0.3659661708772182, 0.36673065784573555, 0.36428158772587776, 0.35813711315989494, 0.3551732242554426, 0.3521101150333881, 0.3481389315545559, 0.345603951382637, 0.34497002248764036, 0.34062345528006555, 0.33748629957437515, 0.33987109460234644, 0.3296687944561243, 0.331255217140913, 0.32596967947781086, 0.32935127680003645, 0.3259941277623177, 0.32347753487229347, 0.3201849966466427, 0.31689560061097144], 'acc': [0.605175, 0.618275, 0.632175, 0.640775, 0.649825, 0.660425, 0.664825, 0.6732, 0.679725, 0.68845, 0.696075, 0.698725, 0.704575, 0.70915, 0.713675, 0.72, 0.724625, 0.729575, 0.7318, 0.7385, 0.7414, 0.74515, 0.753625, 0.75415, 0.7542, 0.763325, 0.766475, 0.7702, 0.770375, 0.77555, 0.7756, 0.7788, 0.7802, 0.7876, 0.7873, 0.7933, 0.794725, 0.7977, 0.799525, 0.803925, 0.804825, 0.804325, 0.807825, 0.8122, 0.812325, 0.817225, 0.8194, 0.818825, 0.820525, 0.823625, 0.826525, 0.82615, 0.827875, 0.82905, 0.829475, 0.8331, 0.833625, 0.835375, 0.838275, 0.84245, 0.841775, 0.8441, 0.844325, 0.848025, 0.848125, 0.846625, 0.850125, 0.8525, 0.852575, 0.85285, 0.855875, 0.858775, 0.861475, 0.85975, 0.8585, 0.862975, 0.862325, 0.8656, 0.8667, 0.869075, 0.870025, 0.868325, 0.8694, 0.872675, 0.873675, 0.8724, 0.875675, 0.874775, 0.8759, 0.8768, 0.877925, 0.87905, 0.881325, 0.879675, 0.882975, 0.881075, 0.882525, 0.88375, 0.88525, 0.88545]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss: 0.5175829311609268\n",
            "validation accuracy: 0.8274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FSqWFhwTMbf5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Architecture (Architecture Four) Training and Test set"
      ]
    },
    {
      "metadata": {
        "id": "E6uwv5TTMa3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1238
        },
        "outputId": "f0ea5eda-d9fc-4955-b470-2828b20e3b9f"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=50000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('Test loss:',History.history['val_loss'][-1])\n",
        "print('Test accuracy:',History.history['val_acc'][-1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 1.9092 - acc: 0.2736\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 1.6202 - acc: 0.3970\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 1.5132 - acc: 0.4452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9ac453309a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             x = self.image_data_generator.apply_transform(\n\u001b[0;32m--> 153\u001b[0;31m                 x.astype(self.dtype), params)\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m    851\u001b[0m                                    \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                                    \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                                    order=self.interpolation_order)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'channel_shift_intensity'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 458\u001b[0;31m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}